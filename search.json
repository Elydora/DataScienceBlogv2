[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html",
    "href": "posts/2022-05-01-chicago-r1.html",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "This report’s intent is to give an initial overview of the recorded incidents of crime in the city of Chicago from 2001 to 2021. The data is provided in a publicly available dataset by the Chicago Police Department. The report is an initial overview about the total numbers of crimes, their types, and development over time. All charts in this report have been created with Apache Superset.\nIt is the first report in a series that is based on the data of this dataset and its purpose is to lay the groundwork for further analysis.\n\n\n\nIntroduction\nData\nAnalysis\nCrime in General\nTrends in Crime\nConclusion\n\n\nfrom IPython.display import Image\nfrom pathlib import Path\n\n\n\n\nThe following report will give an overview on the development of crime counts in the city of Chicago from 2001 to 2021. This analysis includes includes a broad overview on the total number of crimes in the dataset, their development over time and the distribution of the types of crime. We will also have a look on the trend of recorded number of crimes overall and in detail.\n\n\n\nThis analysis is based on the reported incidents of crime in the City of Chicago. The dataset starts in the year of 2001 and is updated daily. It only excludes the most recent seven days. The data is provided by the Chicago Police Department itself. This dataset records among others the date and time of the incident, detailed information on the location, the crime type and description, if an arrest was made and if it was a domestic crime.\nThis dataset is publicly available on the Chicago Data Portal: - https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2\nThe accuracy, completeness, timeliness or correct sequencing of the provided records is not guaranteed. So comparisons of over time created with it should be taken with a grain of salt. In addition, older records are subject to change.\n\n\n\n\n\nAt first let us take a look on the total amount of crimes committed and what their primary types are. From 2001 to 2021 there have been a total of 7.47 million recorded crimes by the Chicago Police Department. Overall these crimes split into 36 different types. The most common crimes are theft, battery, criminal damage and cases involving narcotics. These four types alone amount to 4.5 million of the 7.47 million records overall, which is 61 %.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('01.jpg')\nImage(filename=path)\n\n\n\n\nNext, we will investigate the development of the crime count per year. Overall there has been a steady decline in the number of recorded crimes since 2001. In the beginning there we roughly 486,000 counted crimes compared to the 206,000 in 2021. The decline in felonies comes although the population has increased by 2 % from 2010 to 2020. It rose from 2.696 million to 2.746 million according to the united status census bureau[1].\n[1] https://www.census.gov/quickfacts/fact/table/chicagocityillinois/POP010210#POP010210\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('02.jpg')\nImage(filename=path)\n\n\n\n\nAnother important distinction to look at is the the percentage of domestic crimes overall. 1.02 million of the total crimes counted were flagged as domestic. This results in a share of 13.66 % of all committed crimes. Further analysis shows that the share per year steadily increases as the absolute number of domestic crimes stagnates. The amount of non-domestic crime continues to decrease since 2001.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('03.jpg')\nImage(filename=path)\n\n\n\n\n\n\n\n\nIn this second part we take a look at trends in the numbers of recorded crime. The next graph shows the development of the total numbers of recorded crimes in a 10 year period from 2011 to 2021. In 2011 there were 351,935 cases compared to 205,742 in 2021. Therefore we can see a decrease of nearly 42 % in recorded incidents.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('04.jpg')\nImage(filename=path)\n\n\n\n\nNext, we created an development overview of the 10 most counted crime types over a 20 year period. In general, most of the types have seen a steady decrease, which is also in accordance to the decrease of overall crime. Theft and Battery have stayed the two most recorded felonies in this entire timespan.\nWhile theft and battery have seen a steady decrease, deceptive practice has seen an increase. Crimes that involve narcotics have reached an all-time low. In 2001 these crimes were the fourth most committed overall. Now they are the least committed out of this ranking. Records involving Criminal Damage have somewhat bottomed out and not been decreasing that much.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('05.jpg')\nImage(filename=path)\n\n\n\n\nIn this last part we compare the development of domestic and non-domestic violence. In 2001 12 % of all committed crimes where domestic, compared to 22 % in 2021. While the amount of non-domestic crime reduced from 427,000 to 161,000, domestic crime only shrank to 44,700 from 58,700. Also, there is a notable increase in domestic crime by 4,800 from 2020 to 2021. This could be influenced by changes in the daily life caused by the COVID-19 pandemic. Aside from that, we can see a steady decrease in number of recorded incidents.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('06.jpg')\nImage(filename=path)\n\n\n\n\n\n\n\nIn general, there was a continuous decrease in the number of recorded crimes since 2001 by 57.6 percent. This comes although the population in Chicago has risen. Despite this decrease took place, in these 20 years domestic crime has been relatively stable and not nearly decreased that much. Hence the non-domestic crime has seen a much larger decline. Theft, Battery and criminal damage have been the three most committed crimes since the beginning. Theft was the most, battery the 2nd and criminal damage the 3rd most recorded type. Crimes involving narcotics have seen the largest decrease. From being the fourth most recorded crime in 2001 to dropping down to the tenth most recorded.\nIn the following reports we will take a further look at the areas in which crimes are committed and their development over time. And in addition I will take a deep dive into crime types and their development."
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#table-of-contents",
    "href": "posts/2022-05-01-chicago-r1.html#table-of-contents",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "Introduction\nData\nAnalysis\nCrime in General\nTrends in Crime\nConclusion\n\n\nfrom IPython.display import Image\nfrom pathlib import Path"
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#introduction",
    "href": "posts/2022-05-01-chicago-r1.html#introduction",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "The following report will give an overview on the development of crime counts in the city of Chicago from 2001 to 2021. This analysis includes includes a broad overview on the total number of crimes in the dataset, their development over time and the distribution of the types of crime. We will also have a look on the trend of recorded number of crimes overall and in detail."
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#data",
    "href": "posts/2022-05-01-chicago-r1.html#data",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "This analysis is based on the reported incidents of crime in the City of Chicago. The dataset starts in the year of 2001 and is updated daily. It only excludes the most recent seven days. The data is provided by the Chicago Police Department itself. This dataset records among others the date and time of the incident, detailed information on the location, the crime type and description, if an arrest was made and if it was a domestic crime.\nThis dataset is publicly available on the Chicago Data Portal: - https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2\nThe accuracy, completeness, timeliness or correct sequencing of the provided records is not guaranteed. So comparisons of over time created with it should be taken with a grain of salt. In addition, older records are subject to change."
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#analysis",
    "href": "posts/2022-05-01-chicago-r1.html#analysis",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "At first let us take a look on the total amount of crimes committed and what their primary types are. From 2001 to 2021 there have been a total of 7.47 million recorded crimes by the Chicago Police Department. Overall these crimes split into 36 different types. The most common crimes are theft, battery, criminal damage and cases involving narcotics. These four types alone amount to 4.5 million of the 7.47 million records overall, which is 61 %.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('01.jpg')\nImage(filename=path)\n\n\n\n\nNext, we will investigate the development of the crime count per year. Overall there has been a steady decline in the number of recorded crimes since 2001. In the beginning there we roughly 486,000 counted crimes compared to the 206,000 in 2021. The decline in felonies comes although the population has increased by 2 % from 2010 to 2020. It rose from 2.696 million to 2.746 million according to the united status census bureau[1].\n[1] https://www.census.gov/quickfacts/fact/table/chicagocityillinois/POP010210#POP010210\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('02.jpg')\nImage(filename=path)\n\n\n\n\nAnother important distinction to look at is the the percentage of domestic crimes overall. 1.02 million of the total crimes counted were flagged as domestic. This results in a share of 13.66 % of all committed crimes. Further analysis shows that the share per year steadily increases as the absolute number of domestic crimes stagnates. The amount of non-domestic crime continues to decrease since 2001.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('03.jpg')\nImage(filename=path)"
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#trends-in-crime",
    "href": "posts/2022-05-01-chicago-r1.html#trends-in-crime",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "In this second part we take a look at trends in the numbers of recorded crime. The next graph shows the development of the total numbers of recorded crimes in a 10 year period from 2011 to 2021. In 2011 there were 351,935 cases compared to 205,742 in 2021. Therefore we can see a decrease of nearly 42 % in recorded incidents.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('04.jpg')\nImage(filename=path)\n\n\n\n\nNext, we created an development overview of the 10 most counted crime types over a 20 year period. In general, most of the types have seen a steady decrease, which is also in accordance to the decrease of overall crime. Theft and Battery have stayed the two most recorded felonies in this entire timespan.\nWhile theft and battery have seen a steady decrease, deceptive practice has seen an increase. Crimes that involve narcotics have reached an all-time low. In 2001 these crimes were the fourth most committed overall. Now they are the least committed out of this ranking. Records involving Criminal Damage have somewhat bottomed out and not been decreasing that much.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('05.jpg')\nImage(filename=path)\n\n\n\n\nIn this last part we compare the development of domestic and non-domestic violence. In 2001 12 % of all committed crimes where domestic, compared to 22 % in 2021. While the amount of non-domestic crime reduced from 427,000 to 161,000, domestic crime only shrank to 44,700 from 58,700. Also, there is a notable increase in domestic crime by 4,800 from 2020 to 2021. This could be influenced by changes in the daily life caused by the COVID-19 pandemic. Aside from that, we can see a steady decrease in number of recorded incidents.\n\npath = Path.cwd().joinpath('images').joinpath('r#1').joinpath\\\n    ('06.jpg')\nImage(filename=path)"
  },
  {
    "objectID": "posts/2022-05-01-chicago-r1.html#conclusion",
    "href": "posts/2022-05-01-chicago-r1.html#conclusion",
    "title": "Analyzing Crime in Chicago",
    "section": "",
    "text": "In general, there was a continuous decrease in the number of recorded crimes since 2001 by 57.6 percent. This comes although the population in Chicago has risen. Despite this decrease took place, in these 20 years domestic crime has been relatively stable and not nearly decreased that much. Hence the non-domestic crime has seen a much larger decline. Theft, Battery and criminal damage have been the three most committed crimes since the beginning. Theft was the most, battery the 2nd and criminal damage the 3rd most recorded type. Crimes involving narcotics have seen the largest decrease. From being the fourth most recorded crime in 2001 to dropping down to the tenth most recorded.\nIn the following reports we will take a further look at the areas in which crimes are committed and their development over time. And in addition I will take a deep dive into crime types and their development."
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html",
    "href": "posts/2021-06-24-capstone-project.html",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "Introduction: Business Problem\nData\nMethodology\nAnalysis\nResults and Discussion\nConclusion\n\n\n\n\nIn this project I will try to give a recommendation on where to open a restaurant in Los Angeles County, CA. In addition, there shall be given a recommendation of which type of restaurant could be opened, based on existing restaurants in the area and generally popular restaurants in the whole county.\nThe decision on where to open a restaurant can be based on many factors, depending on the target group. For example, one could look for very dense populated areas, or areas with lots of wealthy citizens. Even the median age of the population can play a role.\nI will make a decision based on the following conditions: - Find the area with a good balance between number of possible customers and a high median income (population is slightly more important than income) - the type of restaurant will be determined by the most recommended categories of food venue in Los Angeles County, CA and the number of already existing venues in the area\n\n\n\nI used three different datasets as basis for my analysis. Using these datasets I am able to work with the following features, among others: - A list of areas in Los Angeles County, CA based on the ZIP code - The number of citizens and households in every area - The estimated median income of every area - The latitude and longitude for every zip code in the county\n\nI combined the following datasets for this: - 2010 Los Angeles Census Data - https://www.kaggle.com/cityofLA/los-angeles-census-data - Median Household Income by Zip Code in 2019 - http://www.laalmanac.com/employment/em12c.php - US Zip Code Latitude and Longitude - https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/information/\nTo analyse the existing food venues in the county, the Foursquare API is used. With this API we can provide the data to answer the following two questions: - What are the most recommended types of restaurants in the county? - What are the existing food venues categories in the area where we want to open a restaurant in?\n\n\n\nFirst, let’s merge all three datasets and get rid of unnecessary information. I will continue to use a single dataframe with the combined datasets as basis for further analysis.\nThe census data and the geodata for the US zip codes are available as csv files that I will read directly into a dataframe. The records for the median household income are available on a website, so I downloaded the data as a html file, which then is used to create a dataframe. As the median income has a dollar sign and can not be converted into a numeric value automatically because of its format, we have to do some data preparation.\n\nimport pandas as pd\nfrom pathlib import Path\ncensus_path = Path.cwd().joinpath('resources').joinpath('2010-census-populations-by-zip-code.csv')\nhtml_path = Path.cwd().joinpath('resources').joinpath('Median Household Income By Zip Code in Los Angeles County, California.html')\nzip_path = Path.cwd().joinpath('resources').joinpath('us-zip-code-latitude-and-longitude.csv')\n\n# Dataset: 2010 Los Angeles Census Data\ndf_census = pd.read_csv(census_path)\n# Dataset: Median Household Income by Zip Code in 2019\ndfs = pd.read_html(html_path)\ndf_income_all = dfs[0]\n# drop areas where the median income is missing\ndf_income_na = df_income_all[df_income_all['Estimated Median Income'].notna()]\n# Next step: clean the values in the median income column to retrieve\n# numeric values that can be used for clustering / calculation\ndf_income = df_income_na.drop(df_income_na[df_income_na[\n                             'Estimated Median Income'] == '---'].index)\ndf_income['Estimated Median Income'] = \\\n    df_income['Estimated Median Income'].map(lambda x: x.lstrip('$'))\ndf_income['Estimated Median Income'] =\\\n    df_income['Estimated Median Income'].str.replace(',','')\ndf_income[\"Estimated Median Income\"] =\\\n    pd.to_numeric(df_income[\"Estimated Median Income\"])\n# Dataset: US Zip Code Latitude and Longitude\ndf_geodata = pd.read_csv(zip_path, sep=';')\n# Let's start by joining the geodata on the income dataset via the zip code\ndf_income_geo = df_census.join(df_income.set_index('Zip Code'), on='Zip Code')\n# Now join the census data with the income dataset and the geodata\ndataset_geo = df_income_geo.join(df_geodata.set_index('Zip'), on='Zip Code',\n                           how='left')\n# Let us only use the columns we need for the further analysis and ignore\n# the rest\nprepared_ds = dataset_geo[[\n  \"Zip Code\", \"City\", \"Community\", \"Estimated Median Income\",\n  \"Longitude\", \"Latitude\", \"Total Population\", \"Median Age\",\n  \"Total Males\", \"Total Females\", \"Total Households\",\n  \"Average Household Size\"]]\n# last stop: let's drop records with missing data\nfinal_ds = prepared_ds.dropna(axis=0)\nfinal_ds.shape\n\n(279, 12)\n\n\nSo the final dataframe now contains 279 areas with 12 features.  Let’s get an overview on how the records are looking:\n\nfinal_ds.head(5)\n\n\n\n\n\n\n\n\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\n\n\n1\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n43360.0\n-118.24878\n33.972914\n57110\n26.6\n28468\n28642\n12971\n4.40\n\n\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n37285.0\n-118.24845\n33.948315\n51223\n25.5\n24876\n26347\n11731\n4.36\n\n\n3\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n40598.0\n-118.27600\n33.962714\n66266\n26.3\n32631\n33635\n15642\n4.22\n\n\n4\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n49675.0\n-118.30755\n34.077110\n62180\n34.8\n31302\n30878\n22547\n2.73\n\n\n5\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n38491.0\n-118.30848\n34.058911\n37681\n33.9\n19299\n18382\n15044\n2.50\n\n\n\n\n\n\n\n\n\n\nNow we will use the Foursquare API to find out what are the most recommended food venues in the county. For this we will go through every single area and get the recommended food venues in the vicinity of the area center.\n\n# first, lets import the necessary libraries and the credentials for the API\nfrom modules import foursquare\nimport requests\nCLIENT_ID = foursquare.CLIENT_ID\nCLIENT_SECRET = foursquare.CLIENT_SECRET\nACCESS_TOKEN = foursquare.ACCESS_TOKEN\nVERSION = '20210514' # Foursquare API version\nLIMIT = 100\n\n\n# first, we use a list of the areas and without columns we don't need\nareas = final_ds.drop(['Estimated Median Income', 'Total ' 'Population',\n                        'Median Age', 'Total Males', 'Total Females',\n                        'Total Households', 'Average Household Size'], 1)\nareas.head()\n\nFutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n\n\n\n\n\n\n\n\n\n\nCluster Label\nZip Code\nCity\nCommunity\nLongitude\nLatitude\n\n\n\n\n1\n2\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n-118.24878\n33.972914\n\n\n2\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n-118.24845\n33.948315\n\n\n3\n2\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n-118.27600\n33.962714\n\n\n4\n2\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n-118.30755\n34.077110\n\n\n5\n2\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n-118.30848\n34.058911\n\n\n\n\n\n\n\nIn the next code block, we will iterate through every area in the dataframe and get up to 50 recommendations per area. For that I use the “explore” endpoint of the Foursquare API. I use the categoryId and sortByPopularity parameters to only request food venues that are sorted by popularity in descending order.\n\nvenues_list = []\nfor index, area in areas.iterrows():\n    url = 'https://api.foursquare' \\\n      '.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},' \\\n      '{}&radius={}&limit={}&offset={}&categoryId={}&sortByPopularity={}'\\\n        .format(\n    CLIENT_ID, CLIENT_SECRET, VERSION, area['Latitude'], area['Longitude'],\n    1000, LIMIT, 0, '4d4b7105d754a06374d81259', 1)\n\n    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n    for v in results:\n        try: # try to extract the city, if there is one in the response\n            city = v['venue']['location']['city']\n        except:\n            city = area['City']\n\n        try: # try to extract the zip code, if there is one\n            postalCode = str(v['venue']['location']['postalCode'])\n        except:\n            postalCode = str(area['Zip Code'])\n        # build a list with all the columns I want to use\n        if postalCode == str(area['Zip Code']):\n            venues_list.append((\n                        area['Zip Code'],\n                        area['Community'],\n                        area['Latitude'],\n                        area['Longitude'],\n                        v['venue']['name'],\n                        v['venue']['categories'][0]['name'],\n                        city ))\n# create a dataframe from the results of the request\nla_venues = pd.DataFrame(venues_list, columns=['Zip Code', 'Community',\n              'Zip Code Latitude', 'Zip Code Longitude', 'Venue',\n              'Venue Category', 'City'])\n\n\nla_venues.head()\n\n\n\n\n\n\n\n\nZip Code\nCommunity\nZip Code Latitude\nZip Code Longitude\nVenue\nVenue Category\nCity\n\n\n\n\n0\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nMi Lindo Nayarit Mariscos\nMexican Restaurant\nLos Angeles\n\n\n1\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nJack in the Box\nFast Food Restaurant\nLos Angeles\n\n\n2\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nMi Lindo Nayarit\nSeafood Restaurant\nLos Angeles\n\n\n3\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nSUBWAY\nSandwich Place\nLos Angeles\n\n\n4\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nEl Senor Taco\nMexican Restaurant\nLos Angeles\n\n\n\n\n\n\n\n\nla_venues[\"Venue\"].count()\n\n8692\n\n\nSo we have found 8,692 recommendations for our 279 areas in Los Angeles County, CA. That are ~31 recommendations per area. Let’s extract the city and venue category and group the data by category, to find out about the distribution of the recommended food venue categories.\n\nvenues = la_venues[['City', 'Venue Category']]\ncategories = venues.groupby('Venue Category').size().to_frame('Count').reset_index()\nsorted = categories.sort_values(by='Count', ascending=False) # Sort by Count\ntop10 = sorted.iloc[0:9] # Show the top 10 categories\ntop10\n\n\n\n\n\n\n\n\nVenue Category\nCount\n\n\n\n\n76\nMexican Restaurant\n833\n\n\n88\nPizza Place\n575\n\n\n40\nFast Food Restaurant\n501\n\n\n22\nChinese Restaurant\n417\n\n\n8\nBakery\n347\n\n\n98\nSandwich Place\n342\n\n\n1\nAmerican Restaurant\n316\n\n\n17\nCafé\n304\n\n\n13\nBurger Joint\n264\n\n\n\n\n\n\n\nAfter that, we will visualize the distribution.\n\nimport plotly.express as px\nfrom IPython.display import HTML, display\ntop15 = sorted.iloc[0:14]\nfig = px.bar(top15, x=\"Venue Category\", y=\"Count\",\n             title='Distribution of recommended food venue categories')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nSo with this data we can tell what food venue categories are recommended the most throughout Los Angeles County, CA. \nWe have prepared the following data, which we will use for further analysis: - a dataframe with areas in LA County, enriched with geodata, median income and census data - a dataframe with the most recommended food venue categories in the county\n\n\n\n\nIn this project we will focus on finding a suitable area for a new restaurant in Los Angeles County, CA. The areas are defined by their US Zip Code. In addition, we will look at the most recommended food venue categories throughout the country, to suggest which type of restaurant could be opened. There won’t be a specific location in the chosen area recommended.\nIn the first step we have merged three different datasets, that provide data on the different areas in Los Angeles County. With this data it is possible to cluster the areas using information like median income, number of households and number of inhabitants. In addition, using Foursquare, we identified the most recommended food venue categories in the county.\nThe second step in the analysis is to cluster (using k-means clustering) the areas in the county and to describe the individual clusters. Using this method we support the process of finding a single area that looks promising for a new restaurant.\nThe third step is to pick a cluster that fits the chosen criteria most. The area shall be chosen under the premise of finding a good balance between estimated median income and number of potential customers. So the target is to find an area that has as many citizens as possible with the highest income possible. After an area was chosen, the distribution of local restaurant types in this area will be analysed. Combining this information with the categories of food venues that are popular throughout the county, a recommendation of the restaurant to open can be given.\n\n\n\n\n\nFirst of all, let’s have a look on our dataset describing the areas.\n\nfinal_ds.head()\n\n\n\n\n\n\n\n\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\n\n\n1\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n43360.0\n-118.24878\n33.972914\n57110\n26.6\n28468\n28642\n12971\n4.40\n\n\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n37285.0\n-118.24845\n33.948315\n51223\n25.5\n24876\n26347\n11731\n4.36\n\n\n3\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n40598.0\n-118.27600\n33.962714\n66266\n26.3\n32631\n33635\n15642\n4.22\n\n\n4\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n49675.0\n-118.30755\n34.077110\n62180\n34.8\n31302\n30878\n22547\n2.73\n\n\n5\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n38491.0\n-118.30848\n34.058911\n37681\n33.9\n19299\n18382\n15044\n2.50\n\n\n\n\n\n\n\nNow we are going to take a look at the areas with the highest income and the highest population.\n\n# sort descending by the income and draw the top 15 areas\nincome_sorted = final_ds.sort_values(by='Estimated Median Income',\n                                     ascending=False)\nincome_top15 = income_sorted.iloc[0:14]\nfig = px.bar(income_top15, x=\"Estimated Median Income\", y=\"City\",\n orientation = \"h\", color='Estimated Median Income',\n             title='Distribution of Estimated Median Income')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n# sort descending by the population and draw the top 15 areas\npop_sorted = final_ds.sort_values(by='Total Population',\n                                     ascending=False)\npop_top15 = pop_sorted.iloc[0:14]\nfig = px.bar(pop_top15, y=\"Total Population\", x=\"City\",\n orientation = \"v\", color='Total Population',\n             title='Distribution of Population')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nAs we are primarily interested in the areas that have a high total population, let us add the income to this graph and get an overview on which areas in this group have the highest income.\n\nfig = px.scatter(pop_top15, x=\"Estimated Median Income\", y=\"Community\",\n                 size=\"Total Population\", log_x=True, color=\"Total Population\")\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nIn this graph the population determines the bubble size. So there are four areas that stand out:\n\n\n\nCity\nPopulation\nMedian Income\n\n\n\n\nNorwalk\n105,6K\n70,7K\n\n\nLake View Terrace, Sylmar\n91,7K\n74K\n\n\nLa Puente, Valinda\n85K\n71,2K\n\n\nHansen Hills, Pacoima\n104K\n64K\n\n\n\nThese four cities / neighbourhoods seem to be suitable areas, based on their combination of population and median income. We are going to see, if this assumption is confirmed going forward.\n\n\n\n\nfrom sklearn.cluster import KMeans\ngrouped_clustering = final_ds.drop(['Zip Code', 'City', 'Community', 'Longitude', 'Latitude', 'Total Males',\n                                    'Total Females'], 1)\ngrouped_clustering.head()\n\nFutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n\n\n\n\n\n\n\n\n\n\nEstimated Median Income\nTotal Population\nMedian Age\nTotal Households\nAverage Household Size\n\n\n\n\n1\n43360.0\n57110\n26.6\n12971\n4.40\n\n\n2\n37285.0\n51223\n25.5\n11731\n4.36\n\n\n3\n40598.0\n66266\n26.3\n15642\n4.22\n\n\n4\n49675.0\n62180\n34.8\n22547\n2.73\n\n\n5\n38491.0\n37681\n33.9\n15044\n2.50\n\n\n\n\n\n\n\n\nsum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    kmeans = KMeans(n_clusters=k, init=\"k-means++\",\n                random_state=0).fit(grouped_clustering)\n    sum_of_squared_distances.append(kmeans.inertia_)\n\n#kmeans.labels_\n\nC:\\Users\\schul\\miniconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning:\n\nKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(K, sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()\n\n\n\n\nAccording to the elbow method I chose a k of 6 going forward. So let’s do the clustering again with the determined k value. Then I will add the cluster labels to my dataset and print out a summarization of the created clusters.\n\n# cluster with the determined K\nkmeans = KMeans(n_clusters=6, init=\"k-means++\",\n                random_state=0).fit(grouped_clustering)\n# add the labels to the dataset\nfinal_ds.insert(0, 'Cluster Label', kmeans.labels_)\n\n\n# create a dataframe for the defined clusters\ncluster_df = final_ds.groupby('Cluster Label').mean()\ncluster_df\n\n\n\n\n\n\n\n\nZip Code\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\nCluster Label\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n90944.044444\n51793.866667\n-118.206034\n34.081385\n18356.955556\n35.786667\n9296.088889\n9060.866667\n6044.355556\n2.850444\n\n\n1\n90624.000000\n155063.444444\n-118.425995\n34.024770\n17967.666667\n43.838889\n8777.833333\n9189.833333\n7020.722222\n2.479444\n\n\n2\n90645.573770\n52440.918033\n-118.253427\n34.038718\n49920.491803\n32.331148\n24696.983607\n25223.508197\n15608.819672\n3.248852\n\n\n3\n91028.756410\n79091.974359\n-118.215469\n34.065151\n29618.141026\n38.174359\n14394.820513\n15223.320513\n10698.910256\n2.776026\n\n\n4\n90971.672727\n105903.872727\n-118.327527\n34.099429\n29382.745455\n41.198182\n14361.127273\n15021.618182\n11328.072727\n2.540727\n\n\n5\n91153.090909\n57912.863636\n-118.190515\n34.113848\n83146.500000\n30.468182\n41257.500000\n41889.000000\n22069.545455\n3.768182\n\n\n\n\n\n\n\nLet us clean this up a bit and add a new column, that will help us to chose a cluster going forward.\n\nclusters = cluster_df[['Estimated Median Income', 'Total Population',\n                       'Median Age', 'Total Households', 'Average Household '\n                                                         'Size']]\n\nclusters['Decision Factor'] = \\\n    ( ( clusters['Total Population'] * 1.2 ) *\n      clusters['Estimated Median Income']) / 100000\nclusters_r = clusters.round(2)\nclusters_r\nclusters_sorted = clusters_r.sort_values(by='Decision Factor', ascending=False)\nclusters_sorted\n\nSettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nEstimated Median Income\nTotal Population\nMedian Age\nTotal Households\nAverage Household Size\nDecision Factor\n\n\nCluster Label\n\n\n\n\n\n\n\n\n\n\n5\n57912.86\n83146.50\n30.47\n22069.55\n3.77\n57783.02\n\n\n4\n105903.87\n29382.75\n41.20\n11328.07\n2.54\n37340.96\n\n\n1\n155063.44\n17967.67\n43.84\n7020.72\n2.48\n33433.54\n\n\n2\n52440.92\n49920.49\n32.33\n15608.82\n3.25\n31414.52\n\n\n3\n79091.97\n29618.14\n38.17\n10698.91\n2.78\n28110.69\n\n\n0\n51793.87\n18356.96\n35.79\n6044.36\n2.85\n11409.33\n\n\n\n\n\n\n\nLooking at these clusters, they can be described as the following:\n\n\n\nName\nIncome\nPopulation\nAge\n\n\n\n\nCluster 4\nHigh\nMedium\nOlder\n\n\nCluster 0\nLow\nLow\nYoung\n\n\nCluster 1\nVery High\nLow\nOlder\n\n\nCluster 5\nMedium\nVery High\nVery Young\n\n\nCluster 2\nLow\nHigh\nVery Young\n\n\nCluster 3\nHigh\nMedium\nYoung\n\n\n\nSo based on this information I am going to choose Cluster 5 for further evaluation and as the cluster where I will pick an area from. This cluster has a medium income combined with a very high population. It also contains the youngest median age, which also can be considered for choosing the food venue category.\n\ncluster5 = final_ds.loc[final_ds['Cluster Label'] == 5, final_ds\n    .columns[[1] + list(range(2, final_ds.shape[1]))]]\ncluster5.shape\n\n(22, 12)\n\n\nThis cluster contains 22 areas in Los Angeles County, CA. We are going to have a look on them on the map using Folium.\n\nfrom geopy.geocoders import Nominatim\n# initialize the map\naddress = 'Los Angeles County, CA'\ngeolocator = Nominatim(user_agent=\"la_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\n\n\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport folium\nimport numpy as np\n# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\ncluster5 = final_ds.loc[final_ds['Cluster Label'] == 5]\n# set color scheme for the clusters, 6 is our number of clusters\nx = np.arange(6)\nys = [i + x + (i*x)**2 for i in range(6)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(cluster5['Latitude'],\n                                  cluster5['Longitude'],\n                                  cluster5['Zip Code'],\n                                  cluster5['Cluster Label']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster],\n        fill=True,\n        fill_color=rainbow[cluster],\n        fill_opacity=0.7).add_to(map_clusters)\n\n#map_clusters\n\n\nfrom IPython.display import Image\nfrom pathlib import Path\npath = Path.cwd().joinpath('png').joinpath('2021-06-24-capstone.png')\nImage(filename=path)\n\n\n\n\nAs one can see, most of our areas in more densely populated areas and in the vicinity of the city of Los Angeles. Now let us add the “decision factor” again and calculate it for every single region in cluster 5.\n\ncluster5['Decision Factor'] = ( ( cluster5['Total Population'] * 1.2 ) *\n                                  cluster5['Estimated Median Income']) / 100000\ncluster5_r = cluster5.round(2)\ncluster5_sorted = cluster5_r.sort_values(by='Decision Factor', ascending=False)\ncluster5_sorted.head(10)\n\nSettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nCluster Label\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\nDecision Factor\n\n\n\n\n132\n5\n90650\nNorwalk\nNorwalk\n70667.0\n-118.08\n33.91\n105549\n32.5\n52364\n53185\n27130\n3.83\n89505.97\n\n\n214\n5\n91342\nSylmar\nLos Angeles (Lake View Terrace, Sylmar), Kagel...\n74050.0\n-118.43\n34.31\n91725\n31.9\n45786\n45939\n23543\n3.83\n81506.84\n\n\n211\n5\n91331\nPacoima\nLos Angeles (Arleta, Hansen Hills, Pacoima)\n63807.0\n-118.42\n34.25\n103689\n29.5\n52358\n51331\n22465\n4.60\n79393.01\n\n\n266\n5\n91744\nLa Puente\nCity of Industry, La Puente, Valinda\n71243.0\n-117.94\n34.03\n85040\n30.9\n42564\n42476\n18648\n4.55\n72702.06\n\n\n309\n5\n93536\nLancaster\nDel Sur, Fairmont, Lancaster, Metler Valley, N...\n79990.0\n-118.33\n34.73\n70918\n34.4\n37804\n33114\n20964\n3.07\n68072.77\n\n\n129\n5\n90631\nLa Habra\nLa Habra Heights\n83629.0\n-117.95\n33.93\n67619\n34.8\n33320\n34299\n21452\n3.13\n67858.91\n\n\n85\n5\n90250\nHawthorne\nHawthorne (Holly Park)\n56304.0\n-118.35\n33.91\n93193\n31.9\n45113\n48080\n31087\n2.98\n62965.66\n\n\n254\n5\n91706\nBaldwin Park\nBaldwin Park, Irwindale\n65755.0\n-117.97\n34.09\n76571\n30.5\n37969\n38602\n17504\n4.35\n60419.11\n\n\n99\n5\n90280\nSouth Gate\nSouth Gate\n52321.0\n-118.19\n33.94\n94396\n29.4\n46321\n48075\n23278\n4.05\n59266.72\n\n\n158\n5\n90805\nLong Beach\nLong Beach (North Long Beach)\n50914.0\n-118.18\n33.87\n93524\n29.0\n45229\n48295\n26056\n3.56\n57140.17\n\n\n\n\n\n\n\n\n# draw the top 5 areas according to income and population\ncluster5_top5 = cluster5_sorted.iloc[0:5]\nfig = px.bar(cluster5_top5, x='Decision Factor', y='Community',\n             color='Average Household Size' )\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nSo there are three areas that stand out: - Norwalk, with a population of 105,6k and an income of $70,6k; it has the oldest median age of the three communities and the largest population. - Lake View Terrace in Sylmar, with a population of 91,7k and an income of $74k; it has the highest income of the group and the lowest population. - Hansen Hills in Pacoima, with a population 104,7k and an income of $63,8k. It has the youngest median age of the three and is very close to Norwalk in terms of population, but it has the lowest income.\nLooking back at the initial analysis we did for all areas in Los Angeles County, we find that these three areas were also part auf the group we found, based on their features. So through the clustering we could confirm our initial findings.\n\n\n\nUsing Foursquare, we are going to query the existing food venues in the three areas.\nWe will use a radius of 4 kilometres around the center of every community. I will also use the city and zip code from the response to filter out results from Foursquare that actually do not belong to the city community we are exploring.\n\nimport itertools\ntop3 = cluster5_sorted.iloc[0:3]\nvenues_list=[]\n# Get the local food venues for all 3 of our communities\nfor _, record in top3.iterrows():\n    offset = 0\n    for _ in itertools.repeat(None, 4):\n        url = 'https://api.foursquare' \\\n              '.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},' \\\n              '{}&radius={}&limit={}&offset={}&categoryId={}'.format(\n            CLIENT_ID, CLIENT_SECRET, VERSION, record['Latitude'],\n            record['Longitude'], 4000, 50, offset, '4d4b7105d754a06374d81259')\n        # increase the offset for the next run\n        offset += 50\n        # try to read the items from the Foursquare response and loop over them\n        try:\n            results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n            for v in results:\n                # get the city name from the Foursquare response, if possible\n                try:\n                    city = v['venue']['location']['city']\n                except:\n                    city = str(record['City'])\n                # get the zip code from the Foursquare response, if possible\n                try:\n                    postalCode = str(v['venue']['location']['postalCode'])\n                except:\n                    postalCode = str(record['Zip Code'])\n\n                venues_list.append((record['Zip Code'], record['Community'],\n                                    record['Latitude'], record['Longitude'],\n                                    v['venue']['name'],\n                                    v['venue']['categories'][0]['name'],\n                                    city, postalCode))\n        except:\n            # there are no more results that Foursquare can deliver\n            break\n# create a dataframe from all venues we have found for all 3 areas\nnearby_venues = pd.DataFrame(venues_list, columns=['Zip Code', 'Community',\n              'Zip Code Latitude', 'Zip Code Longitude', 'Venue',\n              'Venue Category', 'City', 'PostalCode'])\nnearby_venues.count()\n\nZip Code              364\nCommunity             364\nZip Code Latitude     364\nZip Code Longitude    364\nVenue                 364\nVenue Category        364\nCity                  364\nPostalCode            364\ndtype: int64\n\n\n\n# only keep the records that belong to our 3 chosen cities\nvenues_cleaned = nearby_venues.loc[\n                 nearby_venues['City'].isin(['Norwalk', 'Sylmar', 'Pacoima'])]\nvenues_cleaned.count()\n\nZip Code              160\nCommunity             160\nZip Code Latitude     160\nZip Code Longitude    160\nVenue                 160\nVenue Category        160\nCity                  160\nPostalCode            160\ndtype: int64\n\n\nWe found 160 food venues across all 3 areas. In the next step we will group the food venues by category and city. We can use the count of food venues per category to visualize the distribution across the communities.\n\n# extract city name and food venue category\ncategs = venues_cleaned[['City', 'Venue Category']]\n# count the number of restaurants per city and category\ncategs_count = categs.groupby(['City', 'Venue Category']).size().to_frame(\n               'Count').reset_index()\n# sort the result by city and count\ncategs_sorted = categs_count.sort_values(by=['City', 'Count'],\n                                         ascending=False)\ncategs_sorted\n\n\n\n\n\n\n\n\nCity\nVenue Category\nCount\n\n\n\n\n44\nSylmar\nMexican Restaurant\n12\n\n\n45\nSylmar\nPizza Place\n7\n\n\n47\nSylmar\nSandwich Place\n6\n\n\n38\nSylmar\nChinese Restaurant\n5\n\n\n35\nSylmar\nAmerican Restaurant\n3\n\n\n43\nSylmar\nFried Chicken Joint\n3\n\n\n39\nSylmar\nDonut Shop\n2\n\n\n40\nSylmar\nFast Food Restaurant\n2\n\n\n41\nSylmar\nFood\n2\n\n\n36\nSylmar\nAsian Restaurant\n1\n\n\n37\nSylmar\nBreakfast Spot\n1\n\n\n42\nSylmar\nFood Court\n1\n\n\n46\nSylmar\nRestaurant\n1\n\n\n48\nSylmar\nSeafood Restaurant\n1\n\n\n49\nSylmar\nSnack Place\n1\n\n\n50\nSylmar\nSushi Restaurant\n1\n\n\n51\nSylmar\nTaco Place\n1\n\n\n52\nSylmar\nThai Restaurant\n1\n\n\n28\nPacoima\nMexican Restaurant\n9\n\n\n25\nPacoima\nFast Food Restaurant\n7\n\n\n31\nPacoima\nSandwich Place\n3\n\n\n32\nPacoima\nTaco Place\n3\n\n\n23\nPacoima\nBurger Joint\n2\n\n\n30\nPacoima\nPizza Place\n2\n\n\n20\nPacoima\nAmerican Restaurant\n1\n\n\n21\nPacoima\nBBQ Joint\n1\n\n\n22\nPacoima\nBreakfast Spot\n1\n\n\n24\nPacoima\nChinese Restaurant\n1\n\n\n26\nPacoima\nFood Court\n1\n\n\n27\nPacoima\nFried Chicken Joint\n1\n\n\n29\nPacoima\nMiddle Eastern Restaurant\n1\n\n\n33\nPacoima\nThai Restaurant\n1\n\n\n34\nPacoima\nWings Joint\n1\n\n\n7\nNorwalk\nFast Food Restaurant\n15\n\n\n13\nNorwalk\nMexican Restaurant\n12\n\n\n15\nNorwalk\nSandwich Place\n8\n\n\n14\nNorwalk\nPizza Place\n7\n\n\n5\nNorwalk\nChinese Restaurant\n5\n\n\n6\nNorwalk\nDonut Shop\n5\n\n\n0\nNorwalk\nAmerican Restaurant\n4\n\n\n1\nNorwalk\nAsian Restaurant\n3\n\n\n4\nNorwalk\nBurger Joint\n3\n\n\n11\nNorwalk\nFried Chicken Joint\n2\n\n\n2\nNorwalk\nBakery\n1\n\n\n3\nNorwalk\nBreakfast Spot\n1\n\n\n8\nNorwalk\nFood\n1\n\n\n9\nNorwalk\nFood Court\n1\n\n\n10\nNorwalk\nFood Truck\n1\n\n\n12\nNorwalk\nKorean Restaurant\n1\n\n\n16\nNorwalk\nSteakhouse\n1\n\n\n17\nNorwalk\nSushi Restaurant\n1\n\n\n18\nNorwalk\nTaco Place\n1\n\n\n19\nNorwalk\nThai Restaurant\n1\n\n\n\n\n\n\n\n\ncategs_graph = categs_sorted.loc[categs_sorted['Count'] &gt; 1]\n\nfig = px.bar(categs_graph, y=\"Venue Category\",\n             x=\"Count\", title='Combined Distribution of Food Venues',\n             orientation='h', color = 'City'\n             )\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nHaving a look at the distribution of food venues across the three areas, we can make the following observations: - Mexican restaurants are the most common food venue overall - Fast Food restaurants are the second most common venue, but Norwalk has by far the most - Pacoima has the least restaurants overall and Norwalk the most, despite both of them are very close in population - There seems to be space for a Chinese or American Restaurant or a Donut Shop in Pacoima - Even sandwich and pizza places are not very common in Pacoima - Opening another fast food restaurant or mexican restaurant does not seem like a good idea\n Again, let us have a look on the most recommended food venues in the county for comparison:\n\ntop15 = sorted.iloc[0:14]\nfig = px.bar(top15, x=\"Venue Category\", y=\"Count\",\n             title='Distribution of recommended food venue categories')\n#fig.show(renderer='notebook_connected')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nBakeries are the fith most recommended venue category, but there is currently a maximum of 1 per area. So this could be a good option in any of the three communities.\nMexican and fast food restaurants are already very common and should not be chosen\nThere is an opportunity for a pizza place or a chinese resaturant in Pacoima\nPacoima in general has few food venues. Looking at the median income, any low price food venues could be a good opportunity.\nNorwalk would be the best option according to population and income, but it is already very crowded with restaurants. A bakery seems to be the best option there.\n\nThere are also multiple options for sushi restaurants, burger joints, japanese or thai restaurants in all three areas. Overall not looking bad!\n\n\n\n\nOur analysis shows that there is a high variability in population, income and median age in the different areas of Los Angeles County, CA. So it was possible to identify multiple areas that fit the criteria of a relatively high median income and a high population. Using census and income data of all areas in Los Angeles County, we did a clustering to identify similar areas. By analysing the formed clusters there have been three areas identified that fit the criteria best. Norwalk, Lake View Terrace in Sylmar and Hansen Hills in Pacoima.\nThey are slightly different in income, population and age and also very different in their local distribution of available food venues. The final area could be picked on which of these factors matters to the stakeholders most. I will pick Norwalk as the final area for a food venue, because it offers the best combination of a high population and a good income out of these three areas.\nBy analysing the most recommended food venue categories across the whole county, we found that mexican restaurants are by far the most often recommended venue. After them pizza places, fast food restaurants, chinese restaurants and bakeries follow in that order. To give a recommendation for a food venue to open in Norwalk, we can compare the local distribution of food venues what was recommended the most in the county. By looking at Norwalk we found that there are already many mexican restaurants (12) and fast food restaurants (15). Pizza places (7) and chinese restaurants (5) area also recommended in a higher number, so opening a restaurant in one of those categories would be better, but there is still some competition. What stands out is that there is currently only one bakery recommended by Foursquare in Norwalk. Looking at the distribution of recommendations in the county, bakeries are the fifth most recommended venue category. Because of this, I would recommend opening a bakery in Norwalk, CA to the stakeholders.\nPurpose of this analysis was to identify a possible area and food venue type for a new restaurant in Los Angeles County, CA based on a very limited amount of factors. Analysing census data and existing food venues is only one part on the way to find a location for opening a new restaurant. Other factors that also play a role are for example available spaces, rent costs, other venues in the area. This analysis serves as a starting point for finding possible locations, but further analysis needs to be done by the stakeholders.\n\n\n\nThe purpose of this project was to find a possible location for a new restaurant in Los Angeles County, CA. The desire from the stakeholders was to identify locations that offer a good balance between median income and number of inhabitants, although income shall be rated slightly more important than population. In addition, the idea was to identify possible food venue categories by comparing recommended venues across the country with the local venues in the different areas. So for this there were census and income data combined to identify areas that fit the criteria. A clustering was performed, to group the communities in Los Angeles County using their income and population. Then the cluster was chosen that fit the former mentioned criteria the most. From this cluster the top 3 areas were chosen, that had the best balance between income and population. This way the best three candidates for a new restaurant location were identified.\nThe next step was to analyze the local food venue categories. For this the local venues in a 4 km radius were identified and grouped. This grouping was then compared with the distribution of the most recommended food venue categories across the whole county. In doing so, opportunities for new restaurants in any of the three chosen communities have been identified.\nThe final decision can be made by the stakeholders, based on the recommendations given in this project. This decision for a locality can be based on income, population or median age of the areas. The decision for a venue category can be based on popular venues across the county, and the gaps in the local food offerings that have been identified."
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#table-of-contents",
    "href": "posts/2021-06-24-capstone-project.html#table-of-contents",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "Introduction: Business Problem\nData\nMethodology\nAnalysis\nResults and Discussion\nConclusion"
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#introduction-business-problem",
    "href": "posts/2021-06-24-capstone-project.html#introduction-business-problem",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "In this project I will try to give a recommendation on where to open a restaurant in Los Angeles County, CA. In addition, there shall be given a recommendation of which type of restaurant could be opened, based on existing restaurants in the area and generally popular restaurants in the whole county.\nThe decision on where to open a restaurant can be based on many factors, depending on the target group. For example, one could look for very dense populated areas, or areas with lots of wealthy citizens. Even the median age of the population can play a role.\nI will make a decision based on the following conditions: - Find the area with a good balance between number of possible customers and a high median income (population is slightly more important than income) - the type of restaurant will be determined by the most recommended categories of food venue in Los Angeles County, CA and the number of already existing venues in the area"
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#data",
    "href": "posts/2021-06-24-capstone-project.html#data",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "I used three different datasets as basis for my analysis. Using these datasets I am able to work with the following features, among others: - A list of areas in Los Angeles County, CA based on the ZIP code - The number of citizens and households in every area - The estimated median income of every area - The latitude and longitude for every zip code in the county\n\nI combined the following datasets for this: - 2010 Los Angeles Census Data - https://www.kaggle.com/cityofLA/los-angeles-census-data - Median Household Income by Zip Code in 2019 - http://www.laalmanac.com/employment/em12c.php - US Zip Code Latitude and Longitude - https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/information/\nTo analyse the existing food venues in the county, the Foursquare API is used. With this API we can provide the data to answer the following two questions: - What are the most recommended types of restaurants in the county? - What are the existing food venues categories in the area where we want to open a restaurant in?\n\n\n\nFirst, let’s merge all three datasets and get rid of unnecessary information. I will continue to use a single dataframe with the combined datasets as basis for further analysis.\nThe census data and the geodata for the US zip codes are available as csv files that I will read directly into a dataframe. The records for the median household income are available on a website, so I downloaded the data as a html file, which then is used to create a dataframe. As the median income has a dollar sign and can not be converted into a numeric value automatically because of its format, we have to do some data preparation.\n\nimport pandas as pd\nfrom pathlib import Path\ncensus_path = Path.cwd().joinpath('resources').joinpath('2010-census-populations-by-zip-code.csv')\nhtml_path = Path.cwd().joinpath('resources').joinpath('Median Household Income By Zip Code in Los Angeles County, California.html')\nzip_path = Path.cwd().joinpath('resources').joinpath('us-zip-code-latitude-and-longitude.csv')\n\n# Dataset: 2010 Los Angeles Census Data\ndf_census = pd.read_csv(census_path)\n# Dataset: Median Household Income by Zip Code in 2019\ndfs = pd.read_html(html_path)\ndf_income_all = dfs[0]\n# drop areas where the median income is missing\ndf_income_na = df_income_all[df_income_all['Estimated Median Income'].notna()]\n# Next step: clean the values in the median income column to retrieve\n# numeric values that can be used for clustering / calculation\ndf_income = df_income_na.drop(df_income_na[df_income_na[\n                             'Estimated Median Income'] == '---'].index)\ndf_income['Estimated Median Income'] = \\\n    df_income['Estimated Median Income'].map(lambda x: x.lstrip('$'))\ndf_income['Estimated Median Income'] =\\\n    df_income['Estimated Median Income'].str.replace(',','')\ndf_income[\"Estimated Median Income\"] =\\\n    pd.to_numeric(df_income[\"Estimated Median Income\"])\n# Dataset: US Zip Code Latitude and Longitude\ndf_geodata = pd.read_csv(zip_path, sep=';')\n# Let's start by joining the geodata on the income dataset via the zip code\ndf_income_geo = df_census.join(df_income.set_index('Zip Code'), on='Zip Code')\n# Now join the census data with the income dataset and the geodata\ndataset_geo = df_income_geo.join(df_geodata.set_index('Zip'), on='Zip Code',\n                           how='left')\n# Let us only use the columns we need for the further analysis and ignore\n# the rest\nprepared_ds = dataset_geo[[\n  \"Zip Code\", \"City\", \"Community\", \"Estimated Median Income\",\n  \"Longitude\", \"Latitude\", \"Total Population\", \"Median Age\",\n  \"Total Males\", \"Total Females\", \"Total Households\",\n  \"Average Household Size\"]]\n# last stop: let's drop records with missing data\nfinal_ds = prepared_ds.dropna(axis=0)\nfinal_ds.shape\n\n(279, 12)\n\n\nSo the final dataframe now contains 279 areas with 12 features.  Let’s get an overview on how the records are looking:\n\nfinal_ds.head(5)\n\n\n\n\n\n\n\n\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\n\n\n1\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n43360.0\n-118.24878\n33.972914\n57110\n26.6\n28468\n28642\n12971\n4.40\n\n\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n37285.0\n-118.24845\n33.948315\n51223\n25.5\n24876\n26347\n11731\n4.36\n\n\n3\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n40598.0\n-118.27600\n33.962714\n66266\n26.3\n32631\n33635\n15642\n4.22\n\n\n4\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n49675.0\n-118.30755\n34.077110\n62180\n34.8\n31302\n30878\n22547\n2.73\n\n\n5\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n38491.0\n-118.30848\n34.058911\n37681\n33.9\n19299\n18382\n15044\n2.50\n\n\n\n\n\n\n\n\n\n\nNow we will use the Foursquare API to find out what are the most recommended food venues in the county. For this we will go through every single area and get the recommended food venues in the vicinity of the area center.\n\n# first, lets import the necessary libraries and the credentials for the API\nfrom modules import foursquare\nimport requests\nCLIENT_ID = foursquare.CLIENT_ID\nCLIENT_SECRET = foursquare.CLIENT_SECRET\nACCESS_TOKEN = foursquare.ACCESS_TOKEN\nVERSION = '20210514' # Foursquare API version\nLIMIT = 100\n\n\n# first, we use a list of the areas and without columns we don't need\nareas = final_ds.drop(['Estimated Median Income', 'Total ' 'Population',\n                        'Median Age', 'Total Males', 'Total Females',\n                        'Total Households', 'Average Household Size'], 1)\nareas.head()\n\nFutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n\n\n\n\n\n\n\n\n\n\nCluster Label\nZip Code\nCity\nCommunity\nLongitude\nLatitude\n\n\n\n\n1\n2\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n-118.24878\n33.972914\n\n\n2\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n-118.24845\n33.948315\n\n\n3\n2\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n-118.27600\n33.962714\n\n\n4\n2\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n-118.30755\n34.077110\n\n\n5\n2\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n-118.30848\n34.058911\n\n\n\n\n\n\n\nIn the next code block, we will iterate through every area in the dataframe and get up to 50 recommendations per area. For that I use the “explore” endpoint of the Foursquare API. I use the categoryId and sortByPopularity parameters to only request food venues that are sorted by popularity in descending order.\n\nvenues_list = []\nfor index, area in areas.iterrows():\n    url = 'https://api.foursquare' \\\n      '.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},' \\\n      '{}&radius={}&limit={}&offset={}&categoryId={}&sortByPopularity={}'\\\n        .format(\n    CLIENT_ID, CLIENT_SECRET, VERSION, area['Latitude'], area['Longitude'],\n    1000, LIMIT, 0, '4d4b7105d754a06374d81259', 1)\n\n    results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n    for v in results:\n        try: # try to extract the city, if there is one in the response\n            city = v['venue']['location']['city']\n        except:\n            city = area['City']\n\n        try: # try to extract the zip code, if there is one\n            postalCode = str(v['venue']['location']['postalCode'])\n        except:\n            postalCode = str(area['Zip Code'])\n        # build a list with all the columns I want to use\n        if postalCode == str(area['Zip Code']):\n            venues_list.append((\n                        area['Zip Code'],\n                        area['Community'],\n                        area['Latitude'],\n                        area['Longitude'],\n                        v['venue']['name'],\n                        v['venue']['categories'][0]['name'],\n                        city ))\n# create a dataframe from the results of the request\nla_venues = pd.DataFrame(venues_list, columns=['Zip Code', 'Community',\n              'Zip Code Latitude', 'Zip Code Longitude', 'Venue',\n              'Venue Category', 'City'])\n\n\nla_venues.head()\n\n\n\n\n\n\n\n\nZip Code\nCommunity\nZip Code Latitude\nZip Code Longitude\nVenue\nVenue Category\nCity\n\n\n\n\n0\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nMi Lindo Nayarit Mariscos\nMexican Restaurant\nLos Angeles\n\n\n1\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nJack in the Box\nFast Food Restaurant\nLos Angeles\n\n\n2\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nMi Lindo Nayarit\nSeafood Restaurant\nLos Angeles\n\n\n3\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nSUBWAY\nSandwich Place\nLos Angeles\n\n\n4\n90001\nLos Angeles (South Los Angeles), Florence-Graham\n33.972914\n-118.24878\nEl Senor Taco\nMexican Restaurant\nLos Angeles\n\n\n\n\n\n\n\n\nla_venues[\"Venue\"].count()\n\n8692\n\n\nSo we have found 8,692 recommendations for our 279 areas in Los Angeles County, CA. That are ~31 recommendations per area. Let’s extract the city and venue category and group the data by category, to find out about the distribution of the recommended food venue categories.\n\nvenues = la_venues[['City', 'Venue Category']]\ncategories = venues.groupby('Venue Category').size().to_frame('Count').reset_index()\nsorted = categories.sort_values(by='Count', ascending=False) # Sort by Count\ntop10 = sorted.iloc[0:9] # Show the top 10 categories\ntop10\n\n\n\n\n\n\n\n\nVenue Category\nCount\n\n\n\n\n76\nMexican Restaurant\n833\n\n\n88\nPizza Place\n575\n\n\n40\nFast Food Restaurant\n501\n\n\n22\nChinese Restaurant\n417\n\n\n8\nBakery\n347\n\n\n98\nSandwich Place\n342\n\n\n1\nAmerican Restaurant\n316\n\n\n17\nCafé\n304\n\n\n13\nBurger Joint\n264\n\n\n\n\n\n\n\nAfter that, we will visualize the distribution.\n\nimport plotly.express as px\nfrom IPython.display import HTML, display\ntop15 = sorted.iloc[0:14]\nfig = px.bar(top15, x=\"Venue Category\", y=\"Count\",\n             title='Distribution of recommended food venue categories')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nSo with this data we can tell what food venue categories are recommended the most throughout Los Angeles County, CA. \nWe have prepared the following data, which we will use for further analysis: - a dataframe with areas in LA County, enriched with geodata, median income and census data - a dataframe with the most recommended food venue categories in the county"
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#methodology",
    "href": "posts/2021-06-24-capstone-project.html#methodology",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "In this project we will focus on finding a suitable area for a new restaurant in Los Angeles County, CA. The areas are defined by their US Zip Code. In addition, we will look at the most recommended food venue categories throughout the country, to suggest which type of restaurant could be opened. There won’t be a specific location in the chosen area recommended.\nIn the first step we have merged three different datasets, that provide data on the different areas in Los Angeles County. With this data it is possible to cluster the areas using information like median income, number of households and number of inhabitants. In addition, using Foursquare, we identified the most recommended food venue categories in the county.\nThe second step in the analysis is to cluster (using k-means clustering) the areas in the county and to describe the individual clusters. Using this method we support the process of finding a single area that looks promising for a new restaurant.\nThe third step is to pick a cluster that fits the chosen criteria most. The area shall be chosen under the premise of finding a good balance between estimated median income and number of potential customers. So the target is to find an area that has as many citizens as possible with the highest income possible. After an area was chosen, the distribution of local restaurant types in this area will be analysed. Combining this information with the categories of food venues that are popular throughout the county, a recommendation of the restaurant to open can be given."
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#analysis",
    "href": "posts/2021-06-24-capstone-project.html#analysis",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "First of all, let’s have a look on our dataset describing the areas.\n\nfinal_ds.head()\n\n\n\n\n\n\n\n\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\n\n\n1\n90001\nLos Angeles\nLos Angeles (South Los Angeles), Florence-Graham\n43360.0\n-118.24878\n33.972914\n57110\n26.6\n28468\n28642\n12971\n4.40\n\n\n2\n90002\nLos Angeles\nLos Angeles (Southeast Los Angeles, Watts)\n37285.0\n-118.24845\n33.948315\n51223\n25.5\n24876\n26347\n11731\n4.36\n\n\n3\n90003\nLos Angeles\nLos Angeles (South Los Angeles, Southeast Los ...\n40598.0\n-118.27600\n33.962714\n66266\n26.3\n32631\n33635\n15642\n4.22\n\n\n4\n90004\nLos Angeles\nLos Angeles (Hancock Park, Rampart Village, Vi...\n49675.0\n-118.30755\n34.077110\n62180\n34.8\n31302\n30878\n22547\n2.73\n\n\n5\n90005\nLos Angeles\nLos Angeles (Hancock Park, Koreatown, Wilshire...\n38491.0\n-118.30848\n34.058911\n37681\n33.9\n19299\n18382\n15044\n2.50\n\n\n\n\n\n\n\nNow we are going to take a look at the areas with the highest income and the highest population.\n\n# sort descending by the income and draw the top 15 areas\nincome_sorted = final_ds.sort_values(by='Estimated Median Income',\n                                     ascending=False)\nincome_top15 = income_sorted.iloc[0:14]\nfig = px.bar(income_top15, x=\"Estimated Median Income\", y=\"City\",\n orientation = \"h\", color='Estimated Median Income',\n             title='Distribution of Estimated Median Income')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n# sort descending by the population and draw the top 15 areas\npop_sorted = final_ds.sort_values(by='Total Population',\n                                     ascending=False)\npop_top15 = pop_sorted.iloc[0:14]\nfig = px.bar(pop_top15, y=\"Total Population\", x=\"City\",\n orientation = \"v\", color='Total Population',\n             title='Distribution of Population')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nAs we are primarily interested in the areas that have a high total population, let us add the income to this graph and get an overview on which areas in this group have the highest income.\n\nfig = px.scatter(pop_top15, x=\"Estimated Median Income\", y=\"Community\",\n                 size=\"Total Population\", log_x=True, color=\"Total Population\")\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nIn this graph the population determines the bubble size. So there are four areas that stand out:\n\n\n\nCity\nPopulation\nMedian Income\n\n\n\n\nNorwalk\n105,6K\n70,7K\n\n\nLake View Terrace, Sylmar\n91,7K\n74K\n\n\nLa Puente, Valinda\n85K\n71,2K\n\n\nHansen Hills, Pacoima\n104K\n64K\n\n\n\nThese four cities / neighbourhoods seem to be suitable areas, based on their combination of population and median income. We are going to see, if this assumption is confirmed going forward.\n\n\n\n\nfrom sklearn.cluster import KMeans\ngrouped_clustering = final_ds.drop(['Zip Code', 'City', 'Community', 'Longitude', 'Latitude', 'Total Males',\n                                    'Total Females'], 1)\ngrouped_clustering.head()\n\nFutureWarning:\n\nIn a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n\n\n\n\n\n\n\n\n\n\nEstimated Median Income\nTotal Population\nMedian Age\nTotal Households\nAverage Household Size\n\n\n\n\n1\n43360.0\n57110\n26.6\n12971\n4.40\n\n\n2\n37285.0\n51223\n25.5\n11731\n4.36\n\n\n3\n40598.0\n66266\n26.3\n15642\n4.22\n\n\n4\n49675.0\n62180\n34.8\n22547\n2.73\n\n\n5\n38491.0\n37681\n33.9\n15044\n2.50\n\n\n\n\n\n\n\n\nsum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    kmeans = KMeans(n_clusters=k, init=\"k-means++\",\n                random_state=0).fit(grouped_clustering)\n    sum_of_squared_distances.append(kmeans.inertia_)\n\n#kmeans.labels_\n\nC:\\Users\\schul\\miniconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:881: UserWarning:\n\nKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(K, sum_of_squared_distances, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Sum_of_squared_distances')\nplt.title('Elbow Method For Optimal k')\nplt.show()\n\n\n\n\nAccording to the elbow method I chose a k of 6 going forward. So let’s do the clustering again with the determined k value. Then I will add the cluster labels to my dataset and print out a summarization of the created clusters.\n\n# cluster with the determined K\nkmeans = KMeans(n_clusters=6, init=\"k-means++\",\n                random_state=0).fit(grouped_clustering)\n# add the labels to the dataset\nfinal_ds.insert(0, 'Cluster Label', kmeans.labels_)\n\n\n# create a dataframe for the defined clusters\ncluster_df = final_ds.groupby('Cluster Label').mean()\ncluster_df\n\n\n\n\n\n\n\n\nZip Code\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\n\n\nCluster Label\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n90944.044444\n51793.866667\n-118.206034\n34.081385\n18356.955556\n35.786667\n9296.088889\n9060.866667\n6044.355556\n2.850444\n\n\n1\n90624.000000\n155063.444444\n-118.425995\n34.024770\n17967.666667\n43.838889\n8777.833333\n9189.833333\n7020.722222\n2.479444\n\n\n2\n90645.573770\n52440.918033\n-118.253427\n34.038718\n49920.491803\n32.331148\n24696.983607\n25223.508197\n15608.819672\n3.248852\n\n\n3\n91028.756410\n79091.974359\n-118.215469\n34.065151\n29618.141026\n38.174359\n14394.820513\n15223.320513\n10698.910256\n2.776026\n\n\n4\n90971.672727\n105903.872727\n-118.327527\n34.099429\n29382.745455\n41.198182\n14361.127273\n15021.618182\n11328.072727\n2.540727\n\n\n5\n91153.090909\n57912.863636\n-118.190515\n34.113848\n83146.500000\n30.468182\n41257.500000\n41889.000000\n22069.545455\n3.768182\n\n\n\n\n\n\n\nLet us clean this up a bit and add a new column, that will help us to chose a cluster going forward.\n\nclusters = cluster_df[['Estimated Median Income', 'Total Population',\n                       'Median Age', 'Total Households', 'Average Household '\n                                                         'Size']]\n\nclusters['Decision Factor'] = \\\n    ( ( clusters['Total Population'] * 1.2 ) *\n      clusters['Estimated Median Income']) / 100000\nclusters_r = clusters.round(2)\nclusters_r\nclusters_sorted = clusters_r.sort_values(by='Decision Factor', ascending=False)\nclusters_sorted\n\nSettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nEstimated Median Income\nTotal Population\nMedian Age\nTotal Households\nAverage Household Size\nDecision Factor\n\n\nCluster Label\n\n\n\n\n\n\n\n\n\n\n5\n57912.86\n83146.50\n30.47\n22069.55\n3.77\n57783.02\n\n\n4\n105903.87\n29382.75\n41.20\n11328.07\n2.54\n37340.96\n\n\n1\n155063.44\n17967.67\n43.84\n7020.72\n2.48\n33433.54\n\n\n2\n52440.92\n49920.49\n32.33\n15608.82\n3.25\n31414.52\n\n\n3\n79091.97\n29618.14\n38.17\n10698.91\n2.78\n28110.69\n\n\n0\n51793.87\n18356.96\n35.79\n6044.36\n2.85\n11409.33\n\n\n\n\n\n\n\nLooking at these clusters, they can be described as the following:\n\n\n\nName\nIncome\nPopulation\nAge\n\n\n\n\nCluster 4\nHigh\nMedium\nOlder\n\n\nCluster 0\nLow\nLow\nYoung\n\n\nCluster 1\nVery High\nLow\nOlder\n\n\nCluster 5\nMedium\nVery High\nVery Young\n\n\nCluster 2\nLow\nHigh\nVery Young\n\n\nCluster 3\nHigh\nMedium\nYoung\n\n\n\nSo based on this information I am going to choose Cluster 5 for further evaluation and as the cluster where I will pick an area from. This cluster has a medium income combined with a very high population. It also contains the youngest median age, which also can be considered for choosing the food venue category.\n\ncluster5 = final_ds.loc[final_ds['Cluster Label'] == 5, final_ds\n    .columns[[1] + list(range(2, final_ds.shape[1]))]]\ncluster5.shape\n\n(22, 12)\n\n\nThis cluster contains 22 areas in Los Angeles County, CA. We are going to have a look on them on the map using Folium.\n\nfrom geopy.geocoders import Nominatim\n# initialize the map\naddress = 'Los Angeles County, CA'\ngeolocator = Nominatim(user_agent=\"la_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\n\n\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport folium\nimport numpy as np\n# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\ncluster5 = final_ds.loc[final_ds['Cluster Label'] == 5]\n# set color scheme for the clusters, 6 is our number of clusters\nx = np.arange(6)\nys = [i + x + (i*x)**2 for i in range(6)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(cluster5['Latitude'],\n                                  cluster5['Longitude'],\n                                  cluster5['Zip Code'],\n                                  cluster5['Cluster Label']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster],\n        fill=True,\n        fill_color=rainbow[cluster],\n        fill_opacity=0.7).add_to(map_clusters)\n\n#map_clusters\n\n\nfrom IPython.display import Image\nfrom pathlib import Path\npath = Path.cwd().joinpath('png').joinpath('2021-06-24-capstone.png')\nImage(filename=path)\n\n\n\n\nAs one can see, most of our areas in more densely populated areas and in the vicinity of the city of Los Angeles. Now let us add the “decision factor” again and calculate it for every single region in cluster 5.\n\ncluster5['Decision Factor'] = ( ( cluster5['Total Population'] * 1.2 ) *\n                                  cluster5['Estimated Median Income']) / 100000\ncluster5_r = cluster5.round(2)\ncluster5_sorted = cluster5_r.sort_values(by='Decision Factor', ascending=False)\ncluster5_sorted.head(10)\n\nSettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nCluster Label\nZip Code\nCity\nCommunity\nEstimated Median Income\nLongitude\nLatitude\nTotal Population\nMedian Age\nTotal Males\nTotal Females\nTotal Households\nAverage Household Size\nDecision Factor\n\n\n\n\n132\n5\n90650\nNorwalk\nNorwalk\n70667.0\n-118.08\n33.91\n105549\n32.5\n52364\n53185\n27130\n3.83\n89505.97\n\n\n214\n5\n91342\nSylmar\nLos Angeles (Lake View Terrace, Sylmar), Kagel...\n74050.0\n-118.43\n34.31\n91725\n31.9\n45786\n45939\n23543\n3.83\n81506.84\n\n\n211\n5\n91331\nPacoima\nLos Angeles (Arleta, Hansen Hills, Pacoima)\n63807.0\n-118.42\n34.25\n103689\n29.5\n52358\n51331\n22465\n4.60\n79393.01\n\n\n266\n5\n91744\nLa Puente\nCity of Industry, La Puente, Valinda\n71243.0\n-117.94\n34.03\n85040\n30.9\n42564\n42476\n18648\n4.55\n72702.06\n\n\n309\n5\n93536\nLancaster\nDel Sur, Fairmont, Lancaster, Metler Valley, N...\n79990.0\n-118.33\n34.73\n70918\n34.4\n37804\n33114\n20964\n3.07\n68072.77\n\n\n129\n5\n90631\nLa Habra\nLa Habra Heights\n83629.0\n-117.95\n33.93\n67619\n34.8\n33320\n34299\n21452\n3.13\n67858.91\n\n\n85\n5\n90250\nHawthorne\nHawthorne (Holly Park)\n56304.0\n-118.35\n33.91\n93193\n31.9\n45113\n48080\n31087\n2.98\n62965.66\n\n\n254\n5\n91706\nBaldwin Park\nBaldwin Park, Irwindale\n65755.0\n-117.97\n34.09\n76571\n30.5\n37969\n38602\n17504\n4.35\n60419.11\n\n\n99\n5\n90280\nSouth Gate\nSouth Gate\n52321.0\n-118.19\n33.94\n94396\n29.4\n46321\n48075\n23278\n4.05\n59266.72\n\n\n158\n5\n90805\nLong Beach\nLong Beach (North Long Beach)\n50914.0\n-118.18\n33.87\n93524\n29.0\n45229\n48295\n26056\n3.56\n57140.17\n\n\n\n\n\n\n\n\n# draw the top 5 areas according to income and population\ncluster5_top5 = cluster5_sorted.iloc[0:5]\nfig = px.bar(cluster5_top5, x='Decision Factor', y='Community',\n             color='Average Household Size' )\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nSo there are three areas that stand out: - Norwalk, with a population of 105,6k and an income of $70,6k; it has the oldest median age of the three communities and the largest population. - Lake View Terrace in Sylmar, with a population of 91,7k and an income of $74k; it has the highest income of the group and the lowest population. - Hansen Hills in Pacoima, with a population 104,7k and an income of $63,8k. It has the youngest median age of the three and is very close to Norwalk in terms of population, but it has the lowest income.\nLooking back at the initial analysis we did for all areas in Los Angeles County, we find that these three areas were also part auf the group we found, based on their features. So through the clustering we could confirm our initial findings.\n\n\n\nUsing Foursquare, we are going to query the existing food venues in the three areas.\nWe will use a radius of 4 kilometres around the center of every community. I will also use the city and zip code from the response to filter out results from Foursquare that actually do not belong to the city community we are exploring.\n\nimport itertools\ntop3 = cluster5_sorted.iloc[0:3]\nvenues_list=[]\n# Get the local food venues for all 3 of our communities\nfor _, record in top3.iterrows():\n    offset = 0\n    for _ in itertools.repeat(None, 4):\n        url = 'https://api.foursquare' \\\n              '.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},' \\\n              '{}&radius={}&limit={}&offset={}&categoryId={}'.format(\n            CLIENT_ID, CLIENT_SECRET, VERSION, record['Latitude'],\n            record['Longitude'], 4000, 50, offset, '4d4b7105d754a06374d81259')\n        # increase the offset for the next run\n        offset += 50\n        # try to read the items from the Foursquare response and loop over them\n        try:\n            results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n            for v in results:\n                # get the city name from the Foursquare response, if possible\n                try:\n                    city = v['venue']['location']['city']\n                except:\n                    city = str(record['City'])\n                # get the zip code from the Foursquare response, if possible\n                try:\n                    postalCode = str(v['venue']['location']['postalCode'])\n                except:\n                    postalCode = str(record['Zip Code'])\n\n                venues_list.append((record['Zip Code'], record['Community'],\n                                    record['Latitude'], record['Longitude'],\n                                    v['venue']['name'],\n                                    v['venue']['categories'][0]['name'],\n                                    city, postalCode))\n        except:\n            # there are no more results that Foursquare can deliver\n            break\n# create a dataframe from all venues we have found for all 3 areas\nnearby_venues = pd.DataFrame(venues_list, columns=['Zip Code', 'Community',\n              'Zip Code Latitude', 'Zip Code Longitude', 'Venue',\n              'Venue Category', 'City', 'PostalCode'])\nnearby_venues.count()\n\nZip Code              364\nCommunity             364\nZip Code Latitude     364\nZip Code Longitude    364\nVenue                 364\nVenue Category        364\nCity                  364\nPostalCode            364\ndtype: int64\n\n\n\n# only keep the records that belong to our 3 chosen cities\nvenues_cleaned = nearby_venues.loc[\n                 nearby_venues['City'].isin(['Norwalk', 'Sylmar', 'Pacoima'])]\nvenues_cleaned.count()\n\nZip Code              160\nCommunity             160\nZip Code Latitude     160\nZip Code Longitude    160\nVenue                 160\nVenue Category        160\nCity                  160\nPostalCode            160\ndtype: int64\n\n\nWe found 160 food venues across all 3 areas. In the next step we will group the food venues by category and city. We can use the count of food venues per category to visualize the distribution across the communities.\n\n# extract city name and food venue category\ncategs = venues_cleaned[['City', 'Venue Category']]\n# count the number of restaurants per city and category\ncategs_count = categs.groupby(['City', 'Venue Category']).size().to_frame(\n               'Count').reset_index()\n# sort the result by city and count\ncategs_sorted = categs_count.sort_values(by=['City', 'Count'],\n                                         ascending=False)\ncategs_sorted\n\n\n\n\n\n\n\n\nCity\nVenue Category\nCount\n\n\n\n\n44\nSylmar\nMexican Restaurant\n12\n\n\n45\nSylmar\nPizza Place\n7\n\n\n47\nSylmar\nSandwich Place\n6\n\n\n38\nSylmar\nChinese Restaurant\n5\n\n\n35\nSylmar\nAmerican Restaurant\n3\n\n\n43\nSylmar\nFried Chicken Joint\n3\n\n\n39\nSylmar\nDonut Shop\n2\n\n\n40\nSylmar\nFast Food Restaurant\n2\n\n\n41\nSylmar\nFood\n2\n\n\n36\nSylmar\nAsian Restaurant\n1\n\n\n37\nSylmar\nBreakfast Spot\n1\n\n\n42\nSylmar\nFood Court\n1\n\n\n46\nSylmar\nRestaurant\n1\n\n\n48\nSylmar\nSeafood Restaurant\n1\n\n\n49\nSylmar\nSnack Place\n1\n\n\n50\nSylmar\nSushi Restaurant\n1\n\n\n51\nSylmar\nTaco Place\n1\n\n\n52\nSylmar\nThai Restaurant\n1\n\n\n28\nPacoima\nMexican Restaurant\n9\n\n\n25\nPacoima\nFast Food Restaurant\n7\n\n\n31\nPacoima\nSandwich Place\n3\n\n\n32\nPacoima\nTaco Place\n3\n\n\n23\nPacoima\nBurger Joint\n2\n\n\n30\nPacoima\nPizza Place\n2\n\n\n20\nPacoima\nAmerican Restaurant\n1\n\n\n21\nPacoima\nBBQ Joint\n1\n\n\n22\nPacoima\nBreakfast Spot\n1\n\n\n24\nPacoima\nChinese Restaurant\n1\n\n\n26\nPacoima\nFood Court\n1\n\n\n27\nPacoima\nFried Chicken Joint\n1\n\n\n29\nPacoima\nMiddle Eastern Restaurant\n1\n\n\n33\nPacoima\nThai Restaurant\n1\n\n\n34\nPacoima\nWings Joint\n1\n\n\n7\nNorwalk\nFast Food Restaurant\n15\n\n\n13\nNorwalk\nMexican Restaurant\n12\n\n\n15\nNorwalk\nSandwich Place\n8\n\n\n14\nNorwalk\nPizza Place\n7\n\n\n5\nNorwalk\nChinese Restaurant\n5\n\n\n6\nNorwalk\nDonut Shop\n5\n\n\n0\nNorwalk\nAmerican Restaurant\n4\n\n\n1\nNorwalk\nAsian Restaurant\n3\n\n\n4\nNorwalk\nBurger Joint\n3\n\n\n11\nNorwalk\nFried Chicken Joint\n2\n\n\n2\nNorwalk\nBakery\n1\n\n\n3\nNorwalk\nBreakfast Spot\n1\n\n\n8\nNorwalk\nFood\n1\n\n\n9\nNorwalk\nFood Court\n1\n\n\n10\nNorwalk\nFood Truck\n1\n\n\n12\nNorwalk\nKorean Restaurant\n1\n\n\n16\nNorwalk\nSteakhouse\n1\n\n\n17\nNorwalk\nSushi Restaurant\n1\n\n\n18\nNorwalk\nTaco Place\n1\n\n\n19\nNorwalk\nThai Restaurant\n1\n\n\n\n\n\n\n\n\ncategs_graph = categs_sorted.loc[categs_sorted['Count'] &gt; 1]\n\nfig = px.bar(categs_graph, y=\"Venue Category\",\n             x=\"Count\", title='Combined Distribution of Food Venues',\n             orientation='h', color = 'City'\n             )\nHTML(fig.to_html(include_plotlyjs='cdn'))\n#fig.show(renderer='notebook_connected')\n\n\n\n\n\n                            \n                                            \n\n\n\n\nHaving a look at the distribution of food venues across the three areas, we can make the following observations: - Mexican restaurants are the most common food venue overall - Fast Food restaurants are the second most common venue, but Norwalk has by far the most - Pacoima has the least restaurants overall and Norwalk the most, despite both of them are very close in population - There seems to be space for a Chinese or American Restaurant or a Donut Shop in Pacoima - Even sandwich and pizza places are not very common in Pacoima - Opening another fast food restaurant or mexican restaurant does not seem like a good idea\n Again, let us have a look on the most recommended food venues in the county for comparison:\n\ntop15 = sorted.iloc[0:14]\nfig = px.bar(top15, x=\"Venue Category\", y=\"Count\",\n             title='Distribution of recommended food venue categories')\n#fig.show(renderer='notebook_connected')\nHTML(fig.to_html(include_plotlyjs='cdn'))\n\n\n\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\nBakeries are the fith most recommended venue category, but there is currently a maximum of 1 per area. So this could be a good option in any of the three communities.\nMexican and fast food restaurants are already very common and should not be chosen\nThere is an opportunity for a pizza place or a chinese resaturant in Pacoima\nPacoima in general has few food venues. Looking at the median income, any low price food venues could be a good opportunity.\nNorwalk would be the best option according to population and income, but it is already very crowded with restaurants. A bakery seems to be the best option there.\n\nThere are also multiple options for sushi restaurants, burger joints, japanese or thai restaurants in all three areas. Overall not looking bad!"
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#results-and-discussion",
    "href": "posts/2021-06-24-capstone-project.html#results-and-discussion",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "Our analysis shows that there is a high variability in population, income and median age in the different areas of Los Angeles County, CA. So it was possible to identify multiple areas that fit the criteria of a relatively high median income and a high population. Using census and income data of all areas in Los Angeles County, we did a clustering to identify similar areas. By analysing the formed clusters there have been three areas identified that fit the criteria best. Norwalk, Lake View Terrace in Sylmar and Hansen Hills in Pacoima.\nThey are slightly different in income, population and age and also very different in their local distribution of available food venues. The final area could be picked on which of these factors matters to the stakeholders most. I will pick Norwalk as the final area for a food venue, because it offers the best combination of a high population and a good income out of these three areas.\nBy analysing the most recommended food venue categories across the whole county, we found that mexican restaurants are by far the most often recommended venue. After them pizza places, fast food restaurants, chinese restaurants and bakeries follow in that order. To give a recommendation for a food venue to open in Norwalk, we can compare the local distribution of food venues what was recommended the most in the county. By looking at Norwalk we found that there are already many mexican restaurants (12) and fast food restaurants (15). Pizza places (7) and chinese restaurants (5) area also recommended in a higher number, so opening a restaurant in one of those categories would be better, but there is still some competition. What stands out is that there is currently only one bakery recommended by Foursquare in Norwalk. Looking at the distribution of recommendations in the county, bakeries are the fifth most recommended venue category. Because of this, I would recommend opening a bakery in Norwalk, CA to the stakeholders.\nPurpose of this analysis was to identify a possible area and food venue type for a new restaurant in Los Angeles County, CA based on a very limited amount of factors. Analysing census data and existing food venues is only one part on the way to find a location for opening a new restaurant. Other factors that also play a role are for example available spaces, rent costs, other venues in the area. This analysis serves as a starting point for finding possible locations, but further analysis needs to be done by the stakeholders."
  },
  {
    "objectID": "posts/2021-06-24-capstone-project.html#conclusion",
    "href": "posts/2021-06-24-capstone-project.html#conclusion",
    "title": "Where to open a Restaurant in LA County, CA?",
    "section": "",
    "text": "The purpose of this project was to find a possible location for a new restaurant in Los Angeles County, CA. The desire from the stakeholders was to identify locations that offer a good balance between median income and number of inhabitants, although income shall be rated slightly more important than population. In addition, the idea was to identify possible food venue categories by comparing recommended venues across the country with the local venues in the different areas. So for this there were census and income data combined to identify areas that fit the criteria. A clustering was performed, to group the communities in Los Angeles County using their income and population. Then the cluster was chosen that fit the former mentioned criteria the most. From this cluster the top 3 areas were chosen, that had the best balance between income and population. This way the best three candidates for a new restaurant location were identified.\nThe next step was to analyze the local food venue categories. For this the local venues in a 4 km radius were identified and grouped. This grouping was then compared with the distribution of the most recommended food venue categories across the whole county. In doing so, opportunities for new restaurants in any of the three chosen communities have been identified.\nThe final decision can be made by the stakeholders, based on the recommendations given in this project. This decision for a locality can be based on income, population or median age of the areas. The decision for a venue category can be based on popular venues across the county, and the gaps in the local food offerings that have been identified."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "SAP developer by day, Python developer by night."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataScienceBlogv2",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nAnalyzing Crime in Chicago\n\n\n\n\n\n\n\ndata_science\n\n\nvisualization\n\n\n\n\nInitial Overview\n\n\n\n\n\n\nMay 1, 2022\n\n\nFelix\n\n\n\n\n\n\n  \n\n\n\n\nPython Short Reference\n\n\n\n\n\n\n\npython\n\n\n\n\nData types, functions, data structures, and classes\n\n\n\n\n\n\nOct 25, 2021\n\n\nFelix\n\n\n\n\n\n\n  \n\n\n\n\nWhere to open a Restaurant in LA County, CA?\n\n\n\n\n\n\n\nibm\n\n\ndata_science\n\n\nml\n\n\nvisualization\n\n\n\n\nFinding a location and type using the Foursquare API\n\n\n\n\n\n\nJun 24, 2021\n\n\nFelix\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html",
    "href": "posts/2021-10-25-python-short-reference.html",
    "title": "Python Short Reference",
    "section": "",
    "text": "# copying with the copy library\nimport copy\nfirst_str = \"Will\"\nsecond_str = copy.copy(first_str)\nprint(first_str)\nprint(second_str)\n\nWill\nWill\n\n\n\n# changing elements via index\nnames = [\"Jan\", \"Felix\", \"Ralph\"]\nsecond_names = names\nsecond_names[1] = \"Maria\"\nprint(names)\nprint(second_names)\n\n['Jan', 'Maria', 'Ralph']\n['Jan', 'Maria', 'Ralph']\n\n\n\n# using copy so index does not change the value in the copied element\nthird_names = copy.copy(names)\nthird_names[0] = \"Julia\"\nprint(names)\nprint(third_names)\n\n['Jan', 'Maria', 'Ralph']\n['Julia', 'Maria', 'Ralph']"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#complex-data-types",
    "href": "posts/2021-10-25-python-short-reference.html#complex-data-types",
    "title": "Python Short Reference",
    "section": "",
    "text": "# copying with the copy library\nimport copy\nfirst_str = \"Will\"\nsecond_str = copy.copy(first_str)\nprint(first_str)\nprint(second_str)\n\nWill\nWill\n\n\n\n# changing elements via index\nnames = [\"Jan\", \"Felix\", \"Ralph\"]\nsecond_names = names\nsecond_names[1] = \"Maria\"\nprint(names)\nprint(second_names)\n\n['Jan', 'Maria', 'Ralph']\n['Jan', 'Maria', 'Ralph']\n\n\n\n# using copy so index does not change the value in the copied element\nthird_names = copy.copy(names)\nthird_names[0] = \"Julia\"\nprint(names)\nprint(third_names)\n\n['Jan', 'Maria', 'Ralph']\n['Julia', 'Maria', 'Ralph']"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#dictionaries-and-sets",
    "href": "posts/2021-10-25-python-short-reference.html#dictionaries-and-sets",
    "title": "Python Short Reference",
    "section": "Dictionaries and Sets",
    "text": "Dictionaries and Sets\n\nDictionaries\n\n# creating a dict\nbike_owners = {\"James\":\"Ducati Monster 1200\",\n               \"Jacob\":\"Ducati Scrambler 1100\"}\n# printing an element\nbike_owners[\"Jacob\"]\n\n\n# using int keys\nint_dict = {1:45, 2:55, 3:65}\nint_dict[1]\n\n45\n\n\n\n# print all keys\nint_dict.keys()\n\ndict_keys([1, 2, 3])\n\n\n\n# mixed keys dictionaries\nmixed_dict = {False: \"Daniel\",\n              \"Aria\":[1,2,3],\n              \"Jacob\":True}\nmixed_dict\n\n{False: 'Daniel', 'Aria': [1, 2, 3], 'Jacob': True}\n\n\n\n# deleting elements\ndel int_dict[3]\nint_dict\n\n{1: 45, 2: 55}\n\n\n\n# Complex data types\nfruits = {\n    \"Banana\":[50,60,75,99],\n    \"Apple\":[48,86,47,25],\n    \"Strawberries\":[70,80,60,65]\n}\nprint(fruits[\"Banana\"])\nprint(fruits[\"Banana\"][3])\nfruits[\"Banana\"][3]=50\nprint(fruits[\"Banana\"][3])\n\n[50, 60, 75, 99]\n99\n50\n\n\n\n# length function for number of elements\nprint(len(fruits))\n# sorting a dict\nprint(sorted(fruits))\n# return key value pairs\nprint(fruits.items())\n\n3\n['Apple', 'Banana', 'Strawberries']\n\n\ndict_items([('Banana', [50, 60, 75, 50]), ('Apple', [48, 86, 47, 25]), ('Strawberries', [70, 80, 60, 65])])\n\n\n\n\nSets\n\n# creating sets\nset_string = {\"Emma\", \"Olivia\", \"Ava\", \"Mia\"}\nprint(set_string) # no intrinsic ordering\nempty_set = set()\nmixed_set = {\"Emmma\", 5, 1.5, True,(1,2,3,4)}\nstudent_set = {\"Emma\", \"Marc\", \"Janine\", \"Emma\"}\nprint(student_set) # duplicates are eliminated\n\n\nstudent_set.add(\"Felix\")\nprint(len(student_set))\nprint(max(student_set))\nstudent_set.remove(\"Felix\")\n\n\n# working with numbers\nnumber1={1,2,3,4,5}\nnumber2={4,5,6,7,8}\nnumber3={7,8,9,10,11}\nprint(number1.union(number2))\nprint(number1.difference(number2))\nprint(number1.isdisjoint(number2))\nprint(number1.isdisjoint(number3))\n\n{1, 2, 3, 4, 5, 6, 7, 8}\n{1, 2, 3}\nFalse\nTrue\n\n\n\n\nLists\n\nempty_list = []\nlist_str=[\"Toyota\",\"VW\",\"BMW\",\"Mercedes\"]\nlist_bool=[True, False, False, True]\nlist_str[1]\n\n'VW'\n\n\n\nprint(list_str[len(list_str)-1])\nprint(list_str[-1])\n\nMercedes\nMercedes\n\n\n\nlist_str[0] = \"Hyundai\"\nlist_str\n\n['Hyundai', 'VW', 'BMW', 'Mercedes']\n\n\n\nlist_str += ['Dacia', 'Ford']\nlist_str\n\n['Hyundai', 'VW', 'BMW', 'Mercedes', 'Dacia', 'Ford']\n\n\n\nlist_str.sort()\nlist_str.reverse()\nlist_str.pop()\n\n'BMW'\n\n\n\nnew_list = list_str.copy()\nlist_str.clear()\nlist_str\ndel list_str\n\n\nlist_2 = sorted(new_list)\nlist_2\n\n['Dacia', 'Ford', 'Hyundai', 'Mercedes', 'VW']\n\n\n\nprint(new_list[0:2])\nprint(new_list[:-1])\n\n['VW', 'Mercedes']\n\n\n\n\"Dacia\" in new_list\n\nTrue\n\n\n\n# Nested Lists\ncar_matrix = [[\"Hennessey Venom GT\", 1244],\n              [\"SSC Ultimate Aero\", 1287],\n              [\"Zenvo ST1\", 1100]]\ncar_matrix\nprint(len(car_matrix))\nprint(len(car_matrix[1]))\nprint(car_matrix[1][0])\n\n3\n2\nSSC Ultimate Aero"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#functions",
    "href": "posts/2021-10-25-python-short-reference.html#functions",
    "title": "Python Short Reference",
    "section": "Functions",
    "text": "Functions\n\nFunctions in general\n\n# defining a function\ncountry = \"USA\"\ndef some_fn():\n    print(\"Country: \", country)\n\n\n# calling a function\nsome_fn()\n\nCountry:  USA\n\n\n\ndef some_fn():\n    global country # interpret the global variable\n    country = \"Bangladesh\"\n    print(country)\nsome_fn()\nprint(country) # global variable has changed\n\nBangladesh\nBangladesh\n\n\n\n# passing by reference, because not reassigned and complex data type\nfruits_list = [\"Apple\", \"Grapes\", \"Mango\", \"Bananas\"]\ndef change_list(fruits_list):\n    fruits_list[0] = \"Kiwi\"\n    fruits_list = [\"Kiwi\"] # does nothing on the outside\n    print(\"Inside the function: \", fruits_list)\n\nchange_list(fruits_list)\nprint()\nprint(\"Outside the function: \", fruits_list)\n\nInside the function:  ['Kiwi']\n\nOutside the function:  ['Kiwi', 'Grapes', 'Mango', 'Bananas']\n\n\n\n# using python functions\nimport math\nprint(math.pi)\n\n3.141592653589793\n\n\n\n# multiple arguments\ndef calculate(*args, fn): # * -&gt; multiple arguments, unpack the args tuple\n    return fn(*args)\n\ndef diameter_circle_fn(r):\n    pass\n\ncalculate(10, fn=diameter_circle_fn)\n\n\ndef area_rectangle_fn(length, breadth):\n    return length * breadth\n\ndef calculate(*args, fn): # * -&gt; multiple arguments, unpack the args tuple\n    return fn(*args)\n\ncalculate(20, 40, fn=area_rectangle_fn)\n\n800\n\n\n\n\nLambdas\n\n# lambdas - functions without names\ndef square(x):\n    return x * x\n\n\nresult = square(5)\n\n\ncube_of = lambda x: x * x * x\nresult = cube_of(3)\nresult\n\n27\n\n\n\nadd = lambda x, y: x + y\nresult = add(5, 10)\nresult\n\n15\n\n\n\n# all in one\n(lambda x: x + 2)(10)\n\n12\n\n\n\n# lambda filter\nnum_list = [1,5,6,7,11,78,99,34,105,214]\nfilter(lambda x: x &gt; 10, num_list)\n\n&lt;filter at 0x2220e96dd30&gt;\n\n\n\ngreater_than_10_list = list(filter(lambda x: x &gt; 10, num_list))\ngreater_than_10_list\n\n[11, 78, 99, 34, 105, 214]\n\n\n\n\nFunctions advanced\n\nRecursion\n\n# Recursion - Invoking Functions - Invoking a function from within itself\ndef hello(name):\n    print(\"Hello\", name)\n    hello(name)\n#hello(\"Ron\") - endless loop\n\n\n# system wide recursion limit\nimport sys\nsys.getrecursionlimit()\n\n3000\n\n\n\n\nGenerators\n\n# Generators - create a sequence that can be iterated over\ndef generator():\n    print(\"One!\")\n    yield 1 # control execution flow\n    print(\"Two!\")\n    yield 2\n    print(\"Three!\")\n    yield 3\ng = generator() # no code execution\ng\n\n&lt;generator object generator at 0x0000013378275970&gt;\n\n\n\nnext(g)\n\nOne!\n\n\n1\n\n\n\ndef generate_even_numbers(limit):\n    for i in range(0, limit, 2):\n        yield i\ng = generate_even_numbers(7)\nnext(g)\n\n0\n\n\n\nnext(g)\n\n2\n\n\n\n\nClosures\n\n# Closures - Function in a function\ndef nested_hello_fn():\n    def hello():\n        print(\"Hello Cathy!\")\n    hello()\nnested_hello_fn()\n\nHello Cathy!\n\n\n\ndef get_hello_fn(): # every closure has its own local state (do not share local variables)\n    def hello():\n        print(\"Hello Cathy!\")\n    return hello\nhello_fn = get_hello_fn()\nhello_fn()\n\nHello Cathy!\n\n\n\n\nDecorators\n\nimport random\n\ndef print_message():\n    print(\"Yohoo! Decorators are cool!\")\n\ndef make_highlighted(func):\n    annotations = [\"-\", \"*\", \"+\"]\n    annotate = random.choice(annotations)\n    print(annotate * 50)\n    func()\n    print(annotate * 50)\nmake_highlighted(print_message)\n\n@make_highlighted # that'S how they are really used\ndef print_a_message():\n    print(\"Now you'll see how decorators are used\")\nprint_a_message\n\n--------------------------------------------------\nYohoo! Decorators are cool!\n--------------------------------------------------\n--------------------------------------------------\nNow you'll see how decorators are used\n--------------------------------------------------\n\n\n\ndef plus_highlight(func):\n    def highlight():\n        print(\"+\"*50)\n        func()\n        print(\"+\"*50)\n    return highlight\n\ndef asterisk_highlight(func):\n    def highlight():\n        print(\"*\"*50)\n        func()\n        print(\"*\"*50)\n    return highlight\n\n@plus_highlight\n@asterisk_highlight\ndef hello():\n    print(\"hello!\")\nhello()\n\n++++++++++++++++++++++++++++++++++++++++++++++++++\n**************************************************\nhello!\n**************************************************\n++++++++++++++++++++++++++++++++++++++++++++++++++"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#data-structures",
    "href": "posts/2021-10-25-python-short-reference.html#data-structures",
    "title": "Python Short Reference",
    "section": "Data Structures",
    "text": "Data Structures\n\nQueues\n\n#Built-in queue\nfrom queue import Queue\nolympics = Queue(5)\nolympics\n\n&lt;queue.Queue at 0x1934fae89d0&gt;\n\n\n\nolympics.put(\"United Statues(USA)\")\nolympics.put(\"Great Britain(GBR)\")\nprint(olympics.empty())\nprint(olympics.full())\nprint(olympics.qsize())\nolympics.put(\"China(CHN)\")\nolympics.put(\"Russia(RUS)\")\nolympics.put(\"Germany(GER)\")\n\nFalse\nFalse\n2\n\n\n\nprint(olympics.full())\nolympics.get()\n\nTrue\n\n\n'United Statues(USA)'\n\n\n\n\nStacks\n\nstack = []\nstack.append(\"United States\")\nstack.append(\"Great Britain\")\nstack.append(\"China\")\nstack\n\n['United States', 'Great Britain', 'China']\n\n\n\nstack.pop()\n\n'China'\n\n\n\n\nLinked Lists\n\nclass Node:\n    def __init__(self, dataval=None, nextval=None):\n        self.dataval = dataval\n        self.nextval = nextval\n\n    def __repr__(self):\n        return repr(self.dataval)\n\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n\n    def __repr__(self): # O(N)\n        nodes = []\n        curr = self.head\n\n        while curr:\n            nodes.append(repr(curr))\n            curr = curr.nextval\n\n        return \"[\" + \"-&gt;\".join(nodes) + \"]\"\n\n    def prepend(self, dataval): # O(1)\n        self.head = Node(dataval=dataval, nextval = self.head)\n\n    def append(self, dataval):\n        if not self.head:\n            self.head = Node(dataval=dataval)\n            return\n\n        curr = self.head\n\n        while curr.nextval:\n            curr = curr.nextval\n\n        curr.nextval = Node(dataval=dataval)\n\n    def add_after(self, middle_dataval, dataval):\n        if middle_dataval is None:\n            print(\"Data to insert after not specified\")\n            return\n\n        curr = self.head\n\n        while curr and curr.dataval != middle_dataval:\n            curr = curr.nextval\n\n        new_node = Node(dataval = dataval)\n\n        new_node.nextval = curr.nextval\n        curr.nextval = new_node\n\n    def find(self, data):\n        curr = self.head\n        while curr and curr.dataval != data:\n            curr = curr.nextval\n\n        return curr\n\n    def remove(self, data):\n        curr = self.head\n        prev = None\n\n        while curr and curr.dataval != data:\n            prev = curr\n            curr = curr.nextval\n\n            if prev is None:\n                self.head = curr.nextval\n            elif curr:\n                prev.nextval = curr.nextval\n                curr.nextval = None\n\n    def reverse(self):\n        curr = self.head\n\n        prev_node = None\n        next_node = None\n\n        while curr:\n            nextval = curr.nextval\n            curr.nextval = prev_node\n\n            prev_node = curr\n\n            curr = nextval\n\n        self.head = prev_node\n\n\nnumbers = LinkedList()\nnumbers.append(\"two\")\nnumbers.append(\"three\")\nnumbers.prepend(\"one\")\nnumbers\n\n['one'-&gt;'two'-&gt;'three']"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#classes-and-inheritance",
    "href": "posts/2021-10-25-python-short-reference.html#classes-and-inheritance",
    "title": "Python Short Reference",
    "section": "Classes and Inheritance",
    "text": "Classes and Inheritance\n\nBasics\n\n# Initializing\n# special methods are marked with __methodname__\nclass Student:\n    def __init__(self, name): # can be anything, but self is standard\n        self.name = name # self refers to the current instance\n        self.mail = name + \".\" + \"@xyz.com\"\n\n\nclass Competition:\n\n    # class variable\n    raise_amount = 1.04\n\n    def __init__(self, name, prize):\n\n        self.name = name\n        self.prize = prize\n\n    def raise_prize(self):\n        self.prize = self.prize * Competition.raise_amount\n\n\ndebate = Competition('Debate', 500)\n\nprint(debate.raise_amount)\n\n1.04\n\n\n\n\nPrivate attributes\n\n# instance and class variables are public by default\n# hack for private attributes:\nclass Dog:\n    def __init__(self, name, breed):\n        self.__name = name\n        self.__breed = breed\n\n    def print_details(self):\n        print('My name is %s and I am a %s' % (self.__name, self.__breed))\n\nd1 = Dog(\"Moje\", \"Golden Retriever\")\nd1.print_details()\n\nMy name is Moje and I am a Golden Retriever\n\n\n\nd1.__name = \"Oba\"\nd1.print_details() # doesn't update\n\nMy name is Moje and I am a Golden Retriever\n\n\n\nd1._Dog__breed = \"Husky\" # makes it harder to change, but can be changed\nd1.print_details()\n\nMy name is Moje and I am a Husky\n\n\n\n\nSpecial Methods\n\nclass Competition:\n\n    def __init__(self, name, country, prize):\n        self.__name = name\n        self.__country = country\n        self.__prize = prize\n\n    def get_name_country(self):\n        return '{} {}'.format(self.__name, self.__country, self.__prize)\n\n    def __repr__(self): # representation for print function\n        return \"Competition: {} held in {}, prize: {}\".format(self.__name, self.__country,\n                                                               self.__prize)\n\n    def __str__(self):\n        return \"'{} - {}'\".format(self.get_name_country(), self.__prize)\n\narchery = Competition(\"Archery\", \"Germany\", 8000)\nrepr(archery)\n\n'Competition: Archery held in Germany, prize: 8000'\n\n\n\nstr(archery) # looks for special method __str__()\n\n\"'Archery Germany - 8000'\"\n\n\n\nint.__add__(1, 2)\n\n3\n\n\n\n\nProperties\n\n# Properties with Decorators\nclass Wrestler:\n    def __init__(self, name):\n        self.__name = name\n\n    @property # this is the method for accessing\n    def name(self):\n        print(\"getter method called\")\n        return self.__name\n\n    @name.setter # this is the method for setting new vals\n    def name(self, value):\n        print(\"setter method called\")\n        self.__name = value\n\n    @name.deleter\n    def name(self):\n        del self.__name\n\nw = Wrestler(\"Kart\")\n\n\nw.name\n\ngetter method called\n\n\n'Kart'\n\n\n\n\nClass Methods / Static Methods\n\nclass Competition:\n\n    __raise_amount = 1.04 # class variable\n\n    def __init__(self, name, country, prize):\n        self.__name = name\n        self.__country = country\n        self.__prize = prize\n\n    def raise_prize(self):\n        self.__prize = self.__prize * self.__raise_amount\n\n    def get_name_country(self):\n        return '{} {}'.format(self.__name, self.__country, self.__prize)\n\n    def __repr__(self): # representation for print function\n        return \"Competition: {} held in {}, prize: {}\".format(self.__name, self.__country,\n                                                               self.__prize)\n    def __str__(self):\n        return \"'{} - {}'\".format(self.get_name_country(), self.__prize)\n\n    @classmethod\n    def get_raise_amount(cls):\n        return cls.__raise_amount\n\n    @classmethod\n    def set_raise_amount(cls, amount):\n        cls.__raise_amount = amount\n\n\nc1 = Competition(\"Running\", \"Germany\", 50000)\nc1.set_raise_amount(2)\nc1.get_raise_amount()\n\n2\n\n\n\nCompetition.get_raise_amount()\n\n2\n\n\n\nclass Rectangle:\n\n    @staticmethod # cannot access class variables\n    def area(x,y):\n        return x * y\n\nRectangle.area(5,5)\n\n25\n\n\n\n\nAbstract Methods\n\nfrom abc import ABC, abstractmethod\n\nclass Hominidae(ABC):\n    @abstractmethod # how to do it\n    def diet(self):\n        pass\n\n    @abstractmethod\n    def walk(self):\n        pass\n\n    def behavior(self):\n        print(\"Blabla\")"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#inheritance",
    "href": "posts/2021-10-25-python-short-reference.html#inheritance",
    "title": "Python Short Reference",
    "section": "Inheritance",
    "text": "Inheritance\n\nclass Shape:\n    def __init__(self, shape_type, color=\"Red\"): # optional\n        self.__type = shape_type\n        self.__color = color\n\n    def get_type(self):\n        return self.__type\n\n    def get_color(self):\n        return self.__color\n\n    def get_area(self):\n        pass\n\n    def get_perimeter(self):\n        pass\n\nclass Circle(Shape):\n    pass\n\ncircle = Circle(\"circle\")\n\ntype(circle)\n\n__main__.Circle\n\n\n\nclass Square(Shape):\n\n    def __init__(self):\n        Shape.__init__(self, \"square\")\n\nsquare = Square()\nsquare.get_type()\n\n'square'\n\n\n\nissubclass(Circle, Shape)\n\nTrue\n\n\n\n# Multiple and Multilevel Inheritance\nclass Father:\n    def height(self):\n        print(\"I have inherited my height from my father\")\n\nclass Mother:\n    def intelligence(self):\n        print(\"I have inherited my intelligence from my mother\")\n\nclass Child(Father, Mother):\n    def experience(self):\n        print(\"My experience are all my own\")\n\nc = Child()\nc.height()\n\nI have inherited my height from my father\n\n\n\nc.intelligence()\n\nI have inherited my intelligence from my mother"
  },
  {
    "objectID": "posts/2021-10-25-python-short-reference.html#creational-design-patterns",
    "href": "posts/2021-10-25-python-short-reference.html#creational-design-patterns",
    "title": "Python Short Reference",
    "section": "Creational Design Patterns",
    "text": "Creational Design Patterns\n\nSingletons\n\na class of which only a single instance can exist\nEnsure a class is instantiated only once, and provide a global point of access to it\n\n\nclass Logger:\n    __instance = None\n\n    def __init__(self):\n        raise RuntimeError('Call get_instance() instead')\n\n    @classmethod\n    def get_instance(cls):\n        if cls.__instance is None :\n            print('No instance exists, creating a new one')\n            cls.__instance = cls.__new__(cls)\n        else:\n            print('A previously created instance exists, returning that same one')\n        return cls.__instance\n\nlogger1 = Logger.get_instance()\nlogger1\n\nPythonic implementation - new is always called first -&gt; it creates the instance - cls is reference to not yet existing instance - init is used to initialize the existing instance -&gt; self is a reference to the instance\n\nclass PythonicLogger:\n    __instance = None\n\n    def __init__(self):\n        print('Object initialized')\n        # put your custom code here\n        # is called every time - could be expensive\n\n    def __new__(cls):\n        if cls.__instance is None:\n            print('No instance exists, creating a new one')\n            cls.__instance = super(PythonicLogger, cls).__new__(cls)\n        else:\n            print('A previously created instance exists, returning that same one')\n        return cls.__instance\n\n\nclass SuperLogger:\n    __instance = None\n\n    def __new__(cls):\n        if cls.__instance is None:\n            print('No instance exists, creating a new one')\n            cls.__instance = super(SuperLogger, cls).__new__(cls)\n            # Place all initialization code here\n        else:\n            print('A previously created instance exists, returning that same one')\n        return cls.__instance\n\n\n\nFactory & Abstract Factory Design Patterns\n\nSeparate the creation of objects from their use\nClass creation or Object creation\nClass-creation patterns use inheritance\nObject-creation patterns use delegation\nFactory method is specified in base class, implemented in derived classes\nCreates an instance of several derived classes\nDefine an interface for creating an object, but let subclasses decide which class to instantiate\nUsed to postpone instantiation - responsibility passes from base class to derived classes\nFactory method -&gt; create an instance of any of many derived classes\nAbstract F. pattern -&gt; create an instance of any one of many families of derived classes\nAbstract Factory: create instances of several families of classes encapsulate platform dependencies\n\n\n# Factory Method\nclass Product:\n    def __init__(self, name, price):\n        self.__name = name\n        self.__price = price\n\n    def get_price(self):\n        return self.__price\n\n\nclass MacBookAir(Product):\n\n    def __init__(self, memory, os):\n        Product.__init__(self, 'MacBookAir', 1031)\n\n        self.__memory = memory\n        self.__os = os\n\n\nclass AppleIPad(Product):\n\n    def __init__(self, generation):\n        Product.__init__(self, 'AppleIPad', 529)\n\n        self.__generation = generation\n\nclass AppleIWatch(Product):\n\n    def __init__(self):\n        Product.__init__(self, 'AppleIWatch', 264)\n\n\nclass ProductFactory:\n\n    @staticmethod\n    def create(item_name, *args):\n\n        if item_name == 'MacBookAir':\n            return MacBookAir(*args)\n        elif item_name == 'AppleIPad':\n            return AppleIPad(*args)\n        elif item_name == 'AppleIWatch':\n            return AppleIWatch(*args)\n\nair = ProductFactory.create('MacBookAir', '16GB', 'Sierra')\nipad = ProductFactory.create('AppleIPad', '2nd')\niwatch = ProductFactory.create('AppleIWatch')\niwatch\n\n&lt;__main__.AppleIWatch at 0x193517d2610&gt;\n\n\nAbstract Factory\nAn abstract factory is a factory that returns factories. A normal factory can be used to create sets of related objects. An abstract factory returns factories. Thus, an abstract factory is used to return factories that can be used to create sets of related objects.\n\nimport abc\nclass Toy(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def show(self):\n        pass\n\nclass Color(metaclass=abc.ABCMeta):\n    @abc.abstractmethod\n    def show_color(self):\n        pass\n\n\nclass Car(Toy):\n    def show(self):\n        print(\"Remote controlled car\")\n\nclass ActionFigure(Toy):\n    def show(self):\n        print(\"Captain America action figure\")\n\nclass ConstructionToy(Toy):\n    def show(self):\n        print(\"Lego\")\n\nclass Red(Color):\n    def show_color(self):\n        print(\"red\")\n\nclass Green(Color):\n    def show_color(self):\n        print(\"green\")\n\nclass Blue(Color):\n    def show_color(self):\n        print(\"blue\")\n\ncar = Car()\n\nred = Red()\n\nred.show_color(), car.show()\n\nred\nRemote controlled car\n\n\n(None, None)\n\n\n\nclass AbstractFactory(metaclass=abc.ABCMeta):\n\n    @abc.abstractmethod\n    def get_color(self):\n        pass\n\n    @abc.abstractmethod\n    def get_toy(self):\n        pass\n\n\n# Create concrete classes implementing the same interface.\n# create Factory classes extending AbstractFactory\nclass ColorfulToysFactory(AbstractFactory):\n\n    def get_toy(self, toy_type):\n        if toy_type == None:\n            return None\n\n        if toy_type == \"car\":\n            return Car()\n        elif toy_type == \"action figure\":\n            return ActionFigure()\n        elif toy_type == \"construction toy\":\n            return ConstructionToy()\n\n        return None\n\n    def get_color(self, color_type):\n        if color_type == None:\n            return None\n\n        if color_type == \"red\":\n            return Red()\n        elif color_type == \"green\":\n            return Green()\n        elif color_type == \"blue\":\n            return Blue()\n\n        return None\n\n\n# Use the FactoryProducer to get AbstractFactory in order to get factories of\n# concrete classes by passing an information such as type\nRED_CAR = 'red_car'\nBLUE_LEGO = 'blue_lego'\nGREEN_ACTION_FIGURE = 'green_action_figure'\n\nclass ColorfulToysProducer:\n\n    __colorful_toys_factory = ColorfulToysFactory()\n\n    @classmethod\n    def get_toy_and_color(cls, choice):\n        toy = None\n        color = None\n\n        if choice == RED_CAR:\n            toy = cls.__colorful_toys_factory.get_toy('car')\n            color = cls.__colorful_toys_factory.get_color('red')\n\n        elif choice == BLUE_LEGO:\n            toy = cls.__colorful_toys_factory.get_toy('construction toy')\n            color = cls.__colorful_toys_factory.get_color('blue')\n\n        elif choice == GREEN_ACTION_FIGURE:\n            toy = cls.__colorful_toys_factory.get_toy('action figure')\n            color = cls.__colorful_toys_factory.get_color('green')\n\n        return toy, color\n\ntoy, color = ColorfulToysProducer.get_toy_and_color(RED_CAR)\ntoy, color\n\n(&lt;__main__.Car at 0x193517f9280&gt;, &lt;__main__.Red at 0x193517f9dc0&gt;)\n\n\n\ntoy, color = ColorfulToysProducer.get_toy_and_color(BLUE_LEGO)\ntoy, color\n\n(&lt;__main__.ConstructionToy at 0x1934fb85fd0&gt;, &lt;__main__.Blue at 0x1934fb855b0&gt;)\n\n\n\n\nBuilder Pattern\nBuilder Pattern - Separate the construction of an object from representation - allow same construction process for many representations - parse a complex representation, create different objects - Consider a SQL query builder class - allows step-by-step creation of a SQL query - Query is a complex entity with many different parts - Applications might build once, run multiple times - Separates object construction from its representation - parse a complex construction process into simple constituent operations\n\nclass Mobile:\n\n    def __init__(self,\n                 name,\n                 weight,\n                 screen_size,\n                 ram,\n                 os,\n                 camera_mp,\n                 battery):\n\n        self.name = name\n        self.weight = weight\n        self.screen_size = screen_size\n        self.ram = ram\n        self.os = os\n        self.camera_mp = camera_mp\n        self.battery = battery\n\n    def show(self):\n        print(\"name:\", self.name)\n        print(\"weight:\", self.weight)\n        print(\"screen_size:\", self.screen_size)\n        print(\"ram:\", self.ram)\n        print(\"os:\", self.os)\n        print(\"camera_mp:\", self.camera_mp)\n        print(\"battery:\", self.battery)\n\n\nsamsung_s10 = Mobile(name=\"Samsung S10\",\n                     weight = \"157g\",\n                     screen_size = \"6.1 inch\",\n                     ram = \"8GB\",\n                     os = \"android 9.0\",\n                     camera_mp = \"12 megapixel\",\n                     battery = \"3400 mAh\")\n\n\nsamsung_s10.show()\n\nname: Samsung S10\nweight: 157g\nscreen_size: 6.1 inch\nram: 8GB\nos: android 9.0\ncamera_mp: 12 megapixel\nbattery: 3400 mAh\n\n\n\nto get rid of the long list of parameters we can have the features in the main program but directly setting attributes in the client program is wrong, it goes against “encapsulate what varies principle”\nthis is prone to errors and maintenance unfriendly\n\n\nclass Mobile():\n\n    def __init__(self):\n\n        self.name = None\n        self.weight = None\n        self.screen_size = None\n        self.ram = None\n        self.os = None\n        self.camera_mp = None\n        self.battery = None\n\n    def show(self):\n        print(\"name:\", self.name)\n        print(\"weight:\", self.weight)\n        print(\"screen_size:\", self.screen_size)\n        print(\"ram:\", self.ram)\n        print(\"os:\", self.os)\n        print(\"camera_mp:\", self.camera_mp)\n        print(\"battery:\", self.battery)\n\ns10 = Mobile()\ns10.name = \"Samsung S10\"\ns10.screen_size = \"6.1 inch\",\ns10.os = \"android 9.0\",\ns10.camera_mp = \"12 megapixel\",\ns10.battery = \"3400 mAh\"\ns10.show()\n\n\n# now the features have been encapsulated in a separate class called MyMobile\n# the build method instantiates a new mobile object and encapsulates setting\n# of attributes\n\nclass MyMobileBuilder():\n\n    def __init__(self):\n        self.__mobile = Mobile()\n\n    def get_mobile(self):\n        return self.__mobile\n\n    def build_name(self, name):\n        self.__mobile.name = name\n\n    def build_memory(self, ram):\n        self.__mobile.ram = ram\n\n    def build_camera(self, camera_mp):\n        self.__mobile.camera_mp = camera_mp\n\n    def build_otherfeatures(self, weight, screen_size, os, battery):\n        self.__mobile.weight = weight\n        self.__mobile.screen_size = screen_size\n        self.__mobile.os = os\n        self.__mobile.battery = battery\n\nbuilder = MyMobileBuilder()\nbuilder.build_name('Samsung S10')\nbuilder.build_memory('8GB')\nbuilder.build_camera('16 megapixels')\nmobile = builder.get_mobile()\nmobile.show()\n\nname: Samsung S10\nweight: None\nscreen_size: None\nram: 8GB\nos: None\ncamera_mp: 16 megapixels\nbattery: None\n\n\n\n# Builder is less valuable in python, because you can specify default values\n\nclass Mobile:\n    def __init__(self,\n                 name,\n                 weight='157gm',\n                 screen_size='5inches',\n                 ram='8GB',\n                 os='Android',\n                 camera_mp='16 megapixels',\n                 battery='3400 mAh'):\n\n        self.name = name\n        self.weight = weight\n        self.screen_size = screen_size\n        self.ram = ram\n        self.os = os\n        self.camera_mp = camera_mp\n        self.battery = battery\n\n    def show(self):\n        print(\"name:\", self.name)\n        print(\"weight:\", self.weight)\n        print(\"screen_size:\", self.screen_size)\n        print(\"ram:\", self.ram)\n        print(\"os:\", self.os)\n        print(\"camera_mp:\", self.camera_mp)\n        print(\"battery:\", self.battery)\n\nsamsung_s10 = Mobile('Samsung S10')\nsamsung_s10.show()\n\nname: Samsung S10\nweight: 157gm\nscreen_size: 5inches\nram: 8GB\nos: Android\ncamera_mp: 16 megapixels\nbattery: 3400 mAh\n\n\n\nsamsung_s8 = Mobile('Samsung S8', screen_size='4.4inches', ram='4GB')\nsamsung_s8.show()\n\nname: Samsung S8\nweight: 157gm\nscreen_size: 4.4inches\nram: 4GB\nos: Android\ncamera_mp: 16 megapixels\nbattery: 3400 mAh\n\n\n\n\nObject Pool Pattern\n\nUsed when the cost of initializing objects is high\nNumber of objects in use at a time is low\nRate of object instantiation is high\nPools used to cache and manage objects\nAvoid creating new objects, when an existing one is available\nReuse objects rather than incur the cost of creating one\ncommon example: thread pools\nsome processes are embarrassingly parallel\nthreads are expensive to create and free up\nuse a thread pool -&gt; mitigates the overhead of pool creation\navoids needless re-instantiation and expensive acquisition of resources\n\n\nclass Connection:\n\n    def __init__(self):\n        self.__is_used = False\n\n        # Imagine a very heavy-duty initialization process here\n        # to set up the database connections and connect\n        self.connect_to_database()\n\n    def acquire(self):\n        self.__is_used = True\n\n    def release(self):\n        self.__is_used = False\n\n    def is_used(self):\n        return self.__is_used\n\n    def connect_to_database(self):\n        pass\n\n\nclass ConnectionPool:\n\n    __instance = None\n\n    def __new__(cls, num_connections):\n        if cls.__instance is None:\n            print('No instance exists, creating a new one')\n\n            cls.__instance = super(ConnectionPool, cls).__new__(cls)\n\n            cls.__instance.__num_connections = num_connections\n            cls.__instance.__connections = []\n\n            for i in range(num_connections):\n                cls.__instance.__connections.append(Connection())\n\n        else:\n            print('A previously created instance exists, returning that same one')\n\n\n        return cls.__instance\n\n\n    def acquire(self):\n        for i in range(self.__num_connections):\n            connection = self.__connections[i]\n\n            if not connection.is_used():\n                connection.acquire()\n                return connection\n\n        return None\n\n    def release(self, connection):\n        if connection.is_used():\n            connection.release()\n\n\npool = ConnectionPool(2)\n\nNo instance exists, creating a new one\n\n\n\npool = ConnectionPool(2)\n\nA previously created instance exists, returning that same one\n\n\n\nconn_1 = pool.acquire()\nconn_1\n\n&lt;__main__.Connection at 0x1935180dd30&gt;\n\n\n\nconn_2 = pool.acquire()\nconn_2\n\n&lt;__main__.Connection at 0x1935180d820&gt;\n\n\n\nconn_3 = pool.acquire()\nconn_3 is None\n\nTrue\n\n\n\npool.release(conn_2)\n\n\nconn_3 = pool.acquire()\nconn_3\n\n&lt;__main__.Connection at 0x1935180d820&gt;"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]